{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "from tensorflow.python.ops.variables import trainable_variables\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train_my = genfromtxt('../UserData/655/trainX_655.csv', delimiter=',')\n",
    "y_train_my = genfromtxt('../UserData/655/trainY_655.csv', delimiter=',')\n",
    "X_test_my = genfromtxt('../UserData/655/testX_655.csv', delimiter=',')\n",
    "y_test_my = genfromtxt('../UserData/655/testY_655.csv', delimiter=',')\n",
    "\n",
    "num_classes_my = 6 # there are 5 classes (1 per rating class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train_my = X_train_my.astype('float32') \n",
    "X_train_my = X_train_my.astype('float32')\n",
    "print(X_train_my.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_my = np_utils.to_categorical(y_train_my, num_classes_my) # One-hot encode the labels\n",
    "\n",
    "Y_test_my = np_utils.to_categorical(y_test_my, num_classes_my) # One-hot encode the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_img_my = Input(shape=(20,))\n",
    "\n",
    "print(input_img_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Relu:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_my = Dense(20, activation='relu')(input_img_my)\n",
    "print(x_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded1_my = Dense(15, activation='relu')(x_my)\n",
    "encoded2_my = Dense(12, activation='relu')(encoded1_my)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_my = Dense(10, activation='relu')(encoded2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded2_my = Dense(12, activation='relu')(y_my)\n",
    "decoded1_my = Dense(15, activation='relu')(decoded2_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_my = Dense(20, activation='sigmoid')(decoded1_my)\n",
    "autoencoder_my = Model(input_img_my, z_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x10d9f0080>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "print(encoder_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_my.compile(optimizer='adadelta', loss='mse') # reporting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 20)\n",
      "(450, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_my.shape)\n",
    "\n",
    "print(X_train_my.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/50\n",
      "450/450 [==============================] - 0s 877us/step - loss: 0.1862 - val_loss: 0.1828\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 0s 617us/step - loss: 0.1800 - val_loss: 0.1727\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 0s 678us/step - loss: 0.1624 - val_loss: 0.1436\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 0s 809us/step - loss: 0.1320 - val_loss: 0.1132\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 0s 647us/step - loss: 0.1078 - val_loss: 0.0967\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 0s 646us/step - loss: 0.0983 - val_loss: 0.0927\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 0s 697us/step - loss: 0.0958 - val_loss: 0.0914\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 0s 746us/step - loss: 0.0947 - val_loss: 0.0907\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 0s 750us/step - loss: 0.0940 - val_loss: 0.0901\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 0s 636us/step - loss: 0.0935 - val_loss: 0.0895\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 0s 691us/step - loss: 0.0930 - val_loss: 0.0891\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 0s 634us/step - loss: 0.0927 - val_loss: 0.0888\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 0s 638us/step - loss: 0.0923 - val_loss: 0.0884\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 0s 629us/step - loss: 0.0920 - val_loss: 0.0881\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 0s 642us/step - loss: 0.0917 - val_loss: 0.0878\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 0s 800us/step - loss: 0.0914 - val_loss: 0.0876\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 0s 706us/step - loss: 0.0911 - val_loss: 0.0873\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 0s 751us/step - loss: 0.0908 - val_loss: 0.0871\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 0s 769us/step - loss: 0.0906 - val_loss: 0.0869\n",
      "Epoch 20/50\n",
      "450/450 [==============================] - 0s 769us/step - loss: 0.0903 - val_loss: 0.0867\n",
      "Epoch 21/50\n",
      "450/450 [==============================] - 0s 680us/step - loss: 0.0901 - val_loss: 0.0865\n",
      "Epoch 22/50\n",
      "450/450 [==============================] - 0s 797us/step - loss: 0.0899 - val_loss: 0.0862\n",
      "Epoch 23/50\n",
      "450/450 [==============================] - 0s 695us/step - loss: 0.0896 - val_loss: 0.0861\n",
      "Epoch 24/50\n",
      "450/450 [==============================] - 0s 753us/step - loss: 0.0894 - val_loss: 0.0859\n",
      "Epoch 25/50\n",
      "450/450 [==============================] - 0s 856us/step - loss: 0.0892 - val_loss: 0.0857\n",
      "Epoch 26/50\n",
      "450/450 [==============================] - 0s 632us/step - loss: 0.0890 - val_loss: 0.0855\n",
      "Epoch 27/50\n",
      "450/450 [==============================] - 0s 758us/step - loss: 0.0888 - val_loss: 0.0853\n",
      "Epoch 28/50\n",
      "450/450 [==============================] - 0s 753us/step - loss: 0.0886 - val_loss: 0.0851\n",
      "Epoch 29/50\n",
      "450/450 [==============================] - 0s 729us/step - loss: 0.0884 - val_loss: 0.0849\n",
      "Epoch 30/50\n",
      "450/450 [==============================] - 0s 815us/step - loss: 0.0882 - val_loss: 0.0847\n",
      "Epoch 31/50\n",
      "450/450 [==============================] - 0s 631us/step - loss: 0.0880 - val_loss: 0.0845\n",
      "Epoch 32/50\n",
      "450/450 [==============================] - 0s 612us/step - loss: 0.0878 - val_loss: 0.0843\n",
      "Epoch 33/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.088 - 0s 696us/step - loss: 0.0876 - val_loss: 0.0841\n",
      "Epoch 34/50\n",
      "450/450 [==============================] - 0s 787us/step - loss: 0.0873 - val_loss: 0.0839\n",
      "Epoch 35/50\n",
      "450/450 [==============================] - 0s 621us/step - loss: 0.0871 - val_loss: 0.0836\n",
      "Epoch 36/50\n",
      "450/450 [==============================] - 0s 768us/step - loss: 0.0868 - val_loss: 0.0834\n",
      "Epoch 37/50\n",
      "450/450 [==============================] - 0s 605us/step - loss: 0.0866 - val_loss: 0.0832\n",
      "Epoch 38/50\n",
      "450/450 [==============================] - 0s 758us/step - loss: 0.0863 - val_loss: 0.0829\n",
      "Epoch 39/50\n",
      "450/450 [==============================] - 0s 761us/step - loss: 0.0860 - val_loss: 0.0826\n",
      "Epoch 40/50\n",
      "450/450 [==============================] - 0s 746us/step - loss: 0.0857 - val_loss: 0.0822\n",
      "Epoch 41/50\n",
      "450/450 [==============================] - 0s 860us/step - loss: 0.0853 - val_loss: 0.0819\n",
      "Epoch 42/50\n",
      "450/450 [==============================] - 0s 843us/step - loss: 0.0849 - val_loss: 0.0815\n",
      "Epoch 43/50\n",
      "450/450 [==============================] - 0s 681us/step - loss: 0.0845 - val_loss: 0.0811\n",
      "Epoch 44/50\n",
      "450/450 [==============================] - 0s 739us/step - loss: 0.0841 - val_loss: 0.0807\n",
      "Epoch 45/50\n",
      "450/450 [==============================] - 0s 823us/step - loss: 0.0836 - val_loss: 0.0801\n",
      "Epoch 46/50\n",
      "450/450 [==============================] - 0s 660us/step - loss: 0.0831 - val_loss: 0.0796\n",
      "Epoch 47/50\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.0825 - val_loss: 0.0791\n",
      "Epoch 48/50\n",
      "450/450 [==============================] - 0s 866us/step - loss: 0.0820 - val_loss: 0.0786\n",
      "Epoch 49/50\n",
      "450/450 [==============================] - 0s 714us/step - loss: 0.0814 - val_loss: 0.0781\n",
      "Epoch 50/50\n",
      "450/450 [==============================] - 0s 657us/step - loss: 0.0809 - val_loss: 0.0776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10da78f60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/50\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.0803 - val_loss: 0.0772\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 0s 611us/step - loss: 0.0798 - val_loss: 0.0766\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 0s 611us/step - loss: 0.0793 - val_loss: 0.0762\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 0s 603us/step - loss: 0.0788 - val_loss: 0.0758\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 0s 613us/step - loss: 0.0784 - val_loss: 0.0754\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 0s 594us/step - loss: 0.0779 - val_loss: 0.0750\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 0s 603us/step - loss: 0.0775 - val_loss: 0.0747\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 0s 611us/step - loss: 0.0771 - val_loss: 0.0744\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 0s 600us/step - loss: 0.0767 - val_loss: 0.0741\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 0s 622us/step - loss: 0.0763 - val_loss: 0.0738\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 0s 610us/step - loss: 0.0760 - val_loss: 0.0735\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 0s 610us/step - loss: 0.0757 - val_loss: 0.0733\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 0s 623us/step - loss: 0.0753 - val_loss: 0.0730\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 0s 681us/step - loss: 0.0750 - val_loss: 0.0727\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 0s 742us/step - loss: 0.0747 - val_loss: 0.0725\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 0s 823us/step - loss: 0.0744 - val_loss: 0.0722\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 0s 868us/step - loss: 0.0740 - val_loss: 0.0720\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 0s 867us/step - loss: 0.0737 - val_loss: 0.0718\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 0s 873us/step - loss: 0.0734 - val_loss: 0.0716\n",
      "Epoch 20/50\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0732 - val_loss: 0.0714\n",
      "Epoch 21/50\n",
      "450/450 [==============================] - 0s 671us/step - loss: 0.0729 - val_loss: 0.0711\n",
      "Epoch 22/50\n",
      "450/450 [==============================] - 0s 783us/step - loss: 0.0726 - val_loss: 0.0709\n",
      "Epoch 23/50\n",
      "450/450 [==============================] - 0s 735us/step - loss: 0.0724 - val_loss: 0.0707\n",
      "Epoch 24/50\n",
      "450/450 [==============================] - 0s 681us/step - loss: 0.0720 - val_loss: 0.0705\n",
      "Epoch 25/50\n",
      "450/450 [==============================] - 0s 806us/step - loss: 0.0718 - val_loss: 0.0702\n",
      "Epoch 26/50\n",
      "450/450 [==============================] - 0s 680us/step - loss: 0.0715 - val_loss: 0.0699\n",
      "Epoch 27/50\n",
      "450/450 [==============================] - 0s 634us/step - loss: 0.0713 - val_loss: 0.0698\n",
      "Epoch 28/50\n",
      "450/450 [==============================] - 0s 572us/step - loss: 0.0710 - val_loss: 0.0696\n",
      "Epoch 29/50\n",
      "450/450 [==============================] - 0s 614us/step - loss: 0.0707 - val_loss: 0.0694\n",
      "Epoch 30/50\n",
      "450/450 [==============================] - 0s 611us/step - loss: 0.0705 - val_loss: 0.0692\n",
      "Epoch 31/50\n",
      "450/450 [==============================] - 0s 619us/step - loss: 0.0703 - val_loss: 0.0689\n",
      "Epoch 32/50\n",
      "450/450 [==============================] - 0s 678us/step - loss: 0.0700 - val_loss: 0.0687\n",
      "Epoch 33/50\n",
      "450/450 [==============================] - 0s 518us/step - loss: 0.0698 - val_loss: 0.0685\n",
      "Epoch 34/50\n",
      "450/450 [==============================] - 0s 865us/step - loss: 0.0695 - val_loss: 0.0684\n",
      "Epoch 35/50\n",
      "450/450 [==============================] - 0s 464us/step - loss: 0.0693 - val_loss: 0.0681\n",
      "Epoch 36/50\n",
      "450/450 [==============================] - 0s 787us/step - loss: 0.0690 - val_loss: 0.0679\n",
      "Epoch 37/50\n",
      "450/450 [==============================] - 0s 750us/step - loss: 0.0688 - val_loss: 0.0676\n",
      "Epoch 38/50\n",
      "450/450 [==============================] - 0s 705us/step - loss: 0.0685 - val_loss: 0.0675\n",
      "Epoch 39/50\n",
      "450/450 [==============================] - 0s 610us/step - loss: 0.0683 - val_loss: 0.0672\n",
      "Epoch 40/50\n",
      "450/450 [==============================] - 0s 630us/step - loss: 0.0681 - val_loss: 0.0670\n",
      "Epoch 41/50\n",
      "450/450 [==============================] - 0s 808us/step - loss: 0.0678 - val_loss: 0.0668\n",
      "Epoch 42/50\n",
      "450/450 [==============================] - 0s 638us/step - loss: 0.0676 - val_loss: 0.0666\n",
      "Epoch 43/50\n",
      "450/450 [==============================] - 0s 740us/step - loss: 0.0673 - val_loss: 0.0664\n",
      "Epoch 44/50\n",
      "450/450 [==============================] - 0s 702us/step - loss: 0.0671 - val_loss: 0.0661\n",
      "Epoch 45/50\n",
      "450/450 [==============================] - 0s 657us/step - loss: 0.0669 - val_loss: 0.0659\n",
      "Epoch 46/50\n",
      "450/450 [==============================] - 0s 627us/step - loss: 0.0666 - val_loss: 0.0657\n",
      "Epoch 47/50\n",
      "450/450 [==============================] - 0s 810us/step - loss: 0.0664 - val_loss: 0.0655\n",
      "Epoch 48/50\n",
      "450/450 [==============================] - 0s 659us/step - loss: 0.0662 - val_loss: 0.0653\n",
      "Epoch 49/50\n",
      "450/450 [==============================] - 0s 828us/step - loss: 0.0659 - val_loss: 0.0652\n",
      "Epoch 50/50\n",
      "450/450 [==============================] - 0s 855us/step - loss: 0.0657 - val_loss: 0.0648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10df904e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "autoencoder_my.compile(optimizer='adadelta', loss='mse') # reporting the loss\n",
    "\n",
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2_my = Dense(6, activation='softmax')(encoder_my.output)\n",
    "newmodel_my = Model(encoder_my.input,out2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newmodel_my.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam', \n",
    "          metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/50\n",
      "450/450 [==============================] - 0s 434us/step - loss: 2.1094 - acc: 0.0822 - val_loss: 2.0338 - val_acc: 0.1073\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 0s 63us/step - loss: 1.9422 - acc: 0.1178 - val_loss: 1.9141 - val_acc: 0.1416\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 0s 59us/step - loss: 1.8083 - acc: 0.1733 - val_loss: 1.8180 - val_acc: 0.2017\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 0s 67us/step - loss: 1.7059 - acc: 0.2867 - val_loss: 1.7400 - val_acc: 0.3133\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 0s 67us/step - loss: 1.6144 - acc: 0.4378 - val_loss: 1.6722 - val_acc: 0.3691\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 0s 75us/step - loss: 1.5414 - acc: 0.4644 - val_loss: 1.6107 - val_acc: 0.4120\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 0s 73us/step - loss: 1.4769 - acc: 0.4822 - val_loss: 1.5552 - val_acc: 0.4378\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 0s 80us/step - loss: 1.4235 - acc: 0.4911 - val_loss: 1.5056 - val_acc: 0.4549\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 0s 61us/step - loss: 1.3762 - acc: 0.4978 - val_loss: 1.4606 - val_acc: 0.4635\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 0s 57us/step - loss: 1.3362 - acc: 0.5067 - val_loss: 1.4193 - val_acc: 0.4807\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 0s 76us/step - loss: 1.2998 - acc: 0.5222 - val_loss: 1.3849 - val_acc: 0.4807\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 0s 74us/step - loss: 1.2693 - acc: 0.5467 - val_loss: 1.3556 - val_acc: 0.5021\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 0s 64us/step - loss: 1.2424 - acc: 0.5600 - val_loss: 1.3309 - val_acc: 0.5193\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 0s 74us/step - loss: 1.2194 - acc: 0.5667 - val_loss: 1.3085 - val_acc: 0.5365\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 0s 97us/step - loss: 1.1970 - acc: 0.5756 - val_loss: 1.2909 - val_acc: 0.5322\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 0s 114us/step - loss: 1.1770 - acc: 0.5867 - val_loss: 1.2748 - val_acc: 0.5451\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 0s 106us/step - loss: 1.1581 - acc: 0.6022 - val_loss: 1.2622 - val_acc: 0.5408\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 0s 132us/step - loss: 1.1409 - acc: 0.6044 - val_loss: 1.2493 - val_acc: 0.5322\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 0s 62us/step - loss: 1.1252 - acc: 0.6022 - val_loss: 1.2394 - val_acc: 0.5365\n",
      "Epoch 20/50\n",
      "450/450 [==============================] - 0s 75us/step - loss: 1.1114 - acc: 0.6022 - val_loss: 1.2296 - val_acc: 0.5365\n",
      "Epoch 21/50\n",
      "450/450 [==============================] - 0s 73us/step - loss: 1.0969 - acc: 0.6044 - val_loss: 1.2213 - val_acc: 0.5365\n",
      "Epoch 22/50\n",
      "450/450 [==============================] - 0s 64us/step - loss: 1.0848 - acc: 0.6022 - val_loss: 1.2137 - val_acc: 0.5408\n",
      "Epoch 23/50\n",
      "450/450 [==============================] - 0s 92us/step - loss: 1.0748 - acc: 0.6000 - val_loss: 1.2057 - val_acc: 0.5451\n",
      "Epoch 24/50\n",
      "450/450 [==============================] - 0s 78us/step - loss: 1.0648 - acc: 0.6022 - val_loss: 1.2010 - val_acc: 0.5494\n",
      "Epoch 25/50\n",
      "450/450 [==============================] - 0s 66us/step - loss: 1.0558 - acc: 0.5978 - val_loss: 1.1988 - val_acc: 0.5494\n",
      "Epoch 26/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.1104 - acc: 0.570 - 0s 88us/step - loss: 1.0481 - acc: 0.6000 - val_loss: 1.1960 - val_acc: 0.5536\n",
      "Epoch 27/50\n",
      "450/450 [==============================] - 0s 82us/step - loss: 1.0417 - acc: 0.5978 - val_loss: 1.1916 - val_acc: 0.5536\n",
      "Epoch 28/50\n",
      "450/450 [==============================] - 0s 83us/step - loss: 1.0349 - acc: 0.5978 - val_loss: 1.1868 - val_acc: 0.5536\n",
      "Epoch 29/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.9515 - acc: 0.640 - 0s 69us/step - loss: 1.0284 - acc: 0.5978 - val_loss: 1.1819 - val_acc: 0.5494\n",
      "Epoch 30/50\n",
      "450/450 [==============================] - 0s 88us/step - loss: 1.0219 - acc: 0.5933 - val_loss: 1.1764 - val_acc: 0.5494\n",
      "Epoch 31/50\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.1011 - acc: 0.531 - 0s 67us/step - loss: 1.0160 - acc: 0.5889 - val_loss: 1.1725 - val_acc: 0.5451\n",
      "Epoch 32/50\n",
      "450/450 [==============================] - 0s 64us/step - loss: 1.0106 - acc: 0.5889 - val_loss: 1.1690 - val_acc: 0.5451\n",
      "Epoch 33/50\n",
      "450/450 [==============================] - 0s 61us/step - loss: 1.0057 - acc: 0.5933 - val_loss: 1.1655 - val_acc: 0.5408\n",
      "Epoch 34/50\n",
      "450/450 [==============================] - 0s 67us/step - loss: 1.0004 - acc: 0.5978 - val_loss: 1.1627 - val_acc: 0.5322\n",
      "Epoch 35/50\n",
      "450/450 [==============================] - 0s 68us/step - loss: 0.9964 - acc: 0.6000 - val_loss: 1.1614 - val_acc: 0.5279\n",
      "Epoch 36/50\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.9920 - acc: 0.6000 - val_loss: 1.1608 - val_acc: 0.5279\n",
      "Epoch 37/50\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.9883 - acc: 0.6000 - val_loss: 1.1578 - val_acc: 0.5365\n",
      "Epoch 38/50\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.9850 - acc: 0.6022 - val_loss: 1.1557 - val_acc: 0.5279\n",
      "Epoch 39/50\n",
      "450/450 [==============================] - 0s 94us/step - loss: 0.9803 - acc: 0.6044 - val_loss: 1.1512 - val_acc: 0.5408\n",
      "Epoch 40/50\n",
      "450/450 [==============================] - 0s 106us/step - loss: 0.9769 - acc: 0.6000 - val_loss: 1.1455 - val_acc: 0.5579\n",
      "Epoch 41/50\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.9737 - acc: 0.6067 - val_loss: 1.1421 - val_acc: 0.5665\n",
      "Epoch 42/50\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.9705 - acc: 0.6022 - val_loss: 1.1392 - val_acc: 0.5665\n",
      "Epoch 43/50\n",
      "450/450 [==============================] - 0s 81us/step - loss: 0.9665 - acc: 0.6067 - val_loss: 1.1368 - val_acc: 0.5665\n",
      "Epoch 44/50\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.9630 - acc: 0.6067 - val_loss: 1.1350 - val_acc: 0.5622\n",
      "Epoch 45/50\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.9593 - acc: 0.6111 - val_loss: 1.1352 - val_acc: 0.5579\n",
      "Epoch 46/50\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.9562 - acc: 0.6111 - val_loss: 1.1324 - val_acc: 0.5622\n",
      "Epoch 47/50\n",
      "450/450 [==============================] - 0s 71us/step - loss: 0.9535 - acc: 0.6178 - val_loss: 1.1306 - val_acc: 0.5622\n",
      "Epoch 48/50\n",
      "450/450 [==============================] - 0s 65us/step - loss: 0.9495 - acc: 0.6089 - val_loss: 1.1244 - val_acc: 0.5579\n",
      "Epoch 49/50\n",
      "450/450 [==============================] - 0s 83us/step - loss: 0.9469 - acc: 0.6200 - val_loss: 1.1214 - val_acc: 0.5622\n",
      "Epoch 50/50\n",
      "450/450 [==============================] - 0s 68us/step - loss: 0.9434 - acc: 0.6222 - val_loss: 1.1200 - val_acc: 0.5708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e6c9c88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel_my.fit(X_train_my, Y_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, Y_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 0s 386us/step\n",
      "[[  4.41696815e-04   3.25706489e-02   3.68512213e-01   3.85676682e-01\n",
      "    2.03143567e-01   9.65522695e-03]\n",
      " [  2.94185570e-03   2.91935187e-02   8.50921422e-02   5.88530004e-01\n",
      "    2.48511985e-01   4.57304753e-02]\n",
      " [  1.52596331e-03   4.75256853e-02   3.68322730e-01   3.95414680e-01\n",
      "    1.71314582e-01   1.58963837e-02]\n",
      " ..., \n",
      " [  6.93435955e-04   4.24253531e-02   3.87381256e-01   4.44005191e-01\n",
      "    1.16046198e-01   9.44862980e-03]\n",
      " [  3.72676353e-04   2.95948405e-02   3.79229575e-01   4.36482221e-01\n",
      "    1.47284746e-01   7.03595858e-03]\n",
      " [  6.05247973e-04   1.84046626e-02   1.40439779e-01   5.20997643e-01\n",
      "    3.02372396e-01   1.71802193e-02]]\n",
      "233/233 [==============================] - 0s 75us/step\n",
      "[3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 4 3 2 2 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 3 2 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 2 2 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 2 2 3 3 3 3 3 3 3 3 2 3 3 3 3 3 2 3 2 3 3 2 3 2 3 3 3 3 3 3 3 3 2 3 3 3 4\n",
      " 3 2 3 3 4 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 3 3 3 3 3 3 3 3\n",
      " 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 4 3 3 3 3 3 3 4 3 3 2 3 3 3 3 3 3 3 3\n",
      " 3 3 2 3 3 3 3 3 3 3 3]\n",
      "233/233 [==============================] - 0s 87us/step\n",
      "[ 2.  3.  2.  2.  2.  3.  3.  3.  4.  3.  3.  3.  3.  3.  3.  3.  3.  2.\n",
      "  4.  4.  2.  3.  3.  2.  2.  3.  3.  3.  4.  3.  3.  2.  2.  2.  3.  5.\n",
      "  2.  3.  3.  3.  3.  2.  2.  3.  2.  2.  3.  3.  3.  3.  4.  3.  4.  2.\n",
      "  4.  2.  2.  5.  3.  3.  3.  2.  3.  4.  3.  3.  3.  4.  3.  3.  3.  3.\n",
      "  5.  3.  3.  2.  4.  3.  3.  3.  3.  3.  3.  2.  2.  4.  5.  3.  3.  3.\n",
      "  3.  3.  5.  3.  3.  4.  3.  3.  3.  2.  3.  2.  2.  3.  4.  3.  3.  2.\n",
      "  2.  2.  3.  2.  2.  2.  2.  3.  3.  2.  2.  2.  3.  2.  3.  4.  4.  3.\n",
      "  3.  3.  3.  2.  3.  2.  2.  4.  2.  2.  4.  3.  3.  2.  2.  2.  2.  2.\n",
      "  3.  3.  2.  4.  4.  2.  3.  2.  3.  3.  3.  3.  3.  2.  3.  3.  3.  3.\n",
      "  2.  4.  3.  4.  3.  4.  3.  3.  2.  3.  5.  3.  3.  4.  2.  2.  3.  3.\n",
      "  3.  2.  3.  4.  3.  4.  3.  4.  2.  2.  4.  3.  3.  2.  4.  3.  3.  4.\n",
      "  3.  3.  2.  3.  2.  4.  1.  4.  3.  2.  3.  3.  3.  4.  2.  3.  3.  2.\n",
      "  3.  2.  3.  4.  3.  3.  4.  4.  1.  3.  3.  3.  3.  4.  3.  2.  4.]\n",
      "Accuracy:  0.570815451667\n",
      "233/233 [==============================] - 0s 47us/step\n",
      "[[  0   1   1   0   0]\n",
      " [  0  17  49   0   0]\n",
      " [  0   7 112   3   0]\n",
      " [  0   0  33   4   0]\n",
      " [  0   0   5   1   0]]\n"
     ]
    }
   ],
   "source": [
    "print(newmodel_my.predict(X_test_my, verbose=1))\n",
    "print(np.argmax(newmodel_my.predict(X_test_my, verbose=1),axis=1))\n",
    "\n",
    "scores_my = newmodel_my.evaluate(X_test_my, Y_test_my, verbose=1) \n",
    "print(y_test_my)\n",
    "print(\"Accuracy: \", scores_my[1])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cfm = confusion_matrix(np.array(y_test_my),np.array(np.argmax(newmodel_my.predict(X_test_my, verbose=1),axis=1)))\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
