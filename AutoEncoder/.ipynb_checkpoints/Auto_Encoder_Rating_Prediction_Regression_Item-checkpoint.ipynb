{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "from tensorflow.python.ops.variables import trainable_variables\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train_my = genfromtxt('../UserData/655/trainX_item_655.csv', delimiter=',')\n",
    "y_train_my = genfromtxt('../UserData/655/trainY_item_655.csv', delimiter=',')\n",
    "X_test_my = genfromtxt('../UserData/655/testX_item_655.csv', delimiter=',')\n",
    "y_test_my = genfromtxt('../UserData/655/testY_item_655.csv', delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train_my = X_train_my.astype('float32') \n",
    "X_train_my = X_train_my.astype('float32')\n",
    "print(X_train_my.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_my = y_train_my\n",
    "\n",
    "Y_test_my = y_test_my\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_img_my = Input(shape=(20,))\n",
    "\n",
    "print(input_img_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Relu:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_my = Dense(20, activation='relu')(input_img_my)\n",
    "print(x_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded1_my = Dense(15, activation='relu')(x_my)\n",
    "encoded2_my = Dense(12, activation='relu')(encoded1_my)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_my = Dense(10, activation='sigmoid')(encoded2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded2_my = Dense(12, activation='relu')(y_my)\n",
    "decoded1_my = Dense(15, activation='relu')(decoded2_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_my = Dense(20, activation='relu')(decoded1_my)\n",
    "autoencoder_my = Model(input_img_my, z_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x10f421128>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "print(encoder_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 20)\n",
      "(402, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_my.shape)\n",
    "\n",
    "print(X_train_my.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "402/402 [==============================] - 0s 733us/step - loss: 1.0004 - val_loss: 0.8917\n",
      "Epoch 2/100\n",
      "402/402 [==============================] - 0s 500us/step - loss: 0.8032 - val_loss: 0.7417\n",
      "Epoch 3/100\n",
      "402/402 [==============================] - 0s 497us/step - loss: 0.7241 - val_loss: 0.7062\n",
      "Epoch 4/100\n",
      "402/402 [==============================] - 0s 548us/step - loss: 0.7129 - val_loss: 0.7000\n",
      "Epoch 5/100\n",
      "402/402 [==============================] - 0s 465us/step - loss: 0.7029 - val_loss: 0.6901\n",
      "Epoch 6/100\n",
      "402/402 [==============================] - 0s 457us/step - loss: 0.6969 - val_loss: 0.6873\n",
      "Epoch 7/100\n",
      "402/402 [==============================] - 0s 456us/step - loss: 0.6924 - val_loss: 0.6814\n",
      "Epoch 8/100\n",
      "402/402 [==============================] - 0s 411us/step - loss: 0.6889 - val_loss: 0.6791\n",
      "Epoch 9/100\n",
      "402/402 [==============================] - 0s 487us/step - loss: 0.6861 - val_loss: 0.6756\n",
      "Epoch 10/100\n",
      "402/402 [==============================] - 0s 492us/step - loss: 0.6843 - val_loss: 0.6750\n",
      "Epoch 11/100\n",
      "402/402 [==============================] - 0s 523us/step - loss: 0.6826 - val_loss: 0.6736\n",
      "Epoch 12/100\n",
      "402/402 [==============================] - 0s 491us/step - loss: 0.6820 - val_loss: 0.6721\n",
      "Epoch 13/100\n",
      "402/402 [==============================] - 0s 501us/step - loss: 0.6811 - val_loss: 0.6718\n",
      "Epoch 14/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.6803 - val_loss: 0.6714\n",
      "Epoch 15/100\n",
      "402/402 [==============================] - 0s 471us/step - loss: 0.6799 - val_loss: 0.6698\n",
      "Epoch 16/100\n",
      "402/402 [==============================] - 0s 602us/step - loss: 0.6790 - val_loss: 0.6697\n",
      "Epoch 17/100\n",
      "402/402 [==============================] - 0s 526us/step - loss: 0.6786 - val_loss: 0.6698\n",
      "Epoch 18/100\n",
      "402/402 [==============================] - 0s 471us/step - loss: 0.6782 - val_loss: 0.6723\n",
      "Epoch 19/100\n",
      "402/402 [==============================] - 0s 536us/step - loss: 0.6778 - val_loss: 0.6729\n",
      "Epoch 20/100\n",
      "402/402 [==============================] - 0s 671us/step - loss: 0.6771 - val_loss: 0.6698\n",
      "Epoch 21/100\n",
      "402/402 [==============================] - 0s 379us/step - loss: 0.6769 - val_loss: 0.6693\n",
      "Epoch 22/100\n",
      "402/402 [==============================] - 0s 593us/step - loss: 0.6765 - val_loss: 0.6671\n",
      "Epoch 23/100\n",
      "402/402 [==============================] - 0s 489us/step - loss: 0.6761 - val_loss: 0.6679\n",
      "Epoch 24/100\n",
      "402/402 [==============================] - 0s 576us/step - loss: 0.6757 - val_loss: 0.6673\n",
      "Epoch 25/100\n",
      "402/402 [==============================] - 0s 553us/step - loss: 0.6756 - val_loss: 0.6664\n",
      "Epoch 26/100\n",
      "402/402 [==============================] - 0s 461us/step - loss: 0.6753 - val_loss: 0.6666\n",
      "Epoch 27/100\n",
      "402/402 [==============================] - 0s 616us/step - loss: 0.6749 - val_loss: 0.6689\n",
      "Epoch 28/100\n",
      "402/402 [==============================] - 0s 431us/step - loss: 0.6748 - val_loss: 0.6650\n",
      "Epoch 29/100\n",
      "402/402 [==============================] - 0s 584us/step - loss: 0.6745 - val_loss: 0.6648\n",
      "Epoch 30/100\n",
      "402/402 [==============================] - 0s 555us/step - loss: 0.6744 - val_loss: 0.6647\n",
      "Epoch 31/100\n",
      "402/402 [==============================] - 0s 498us/step - loss: 0.6741 - val_loss: 0.6651\n",
      "Epoch 32/100\n",
      "402/402 [==============================] - 0s 518us/step - loss: 0.6741 - val_loss: 0.6645\n",
      "Epoch 33/100\n",
      "402/402 [==============================] - 0s 511us/step - loss: 0.6738 - val_loss: 0.6658\n",
      "Epoch 34/100\n",
      "402/402 [==============================] - 0s 432us/step - loss: 0.6736 - val_loss: 0.6644\n",
      "Epoch 35/100\n",
      "402/402 [==============================] - 0s 421us/step - loss: 0.6735 - val_loss: 0.6647\n",
      "Epoch 36/100\n",
      "402/402 [==============================] - 0s 454us/step - loss: 0.6731 - val_loss: 0.6661\n",
      "Epoch 37/100\n",
      "402/402 [==============================] - 0s 610us/step - loss: 0.6731 - val_loss: 0.6665\n",
      "Epoch 38/100\n",
      "402/402 [==============================] - 0s 483us/step - loss: 0.6730 - val_loss: 0.6714\n",
      "Epoch 39/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.6728 - val_loss: 0.6631\n",
      "Epoch 40/100\n",
      "402/402 [==============================] - 0s 608us/step - loss: 0.6725 - val_loss: 0.6627\n",
      "Epoch 41/100\n",
      "402/402 [==============================] - 0s 436us/step - loss: 0.6724 - val_loss: 0.6651\n",
      "Epoch 42/100\n",
      "402/402 [==============================] - 0s 430us/step - loss: 0.6721 - val_loss: 0.6619\n",
      "Epoch 43/100\n",
      "402/402 [==============================] - 0s 441us/step - loss: 0.6721 - val_loss: 0.6622\n",
      "Epoch 44/100\n",
      "402/402 [==============================] - 0s 463us/step - loss: 0.6718 - val_loss: 0.6633\n",
      "Epoch 45/100\n",
      "402/402 [==============================] - 0s 455us/step - loss: 0.6715 - val_loss: 0.6625\n",
      "Epoch 46/100\n",
      "402/402 [==============================] - 0s 435us/step - loss: 0.6711 - val_loss: 0.6609\n",
      "Epoch 47/100\n",
      "402/402 [==============================] - 0s 514us/step - loss: 0.6708 - val_loss: 0.6640\n",
      "Epoch 48/100\n",
      "402/402 [==============================] - 0s 506us/step - loss: 0.6706 - val_loss: 0.6597\n",
      "Epoch 49/100\n",
      "402/402 [==============================] - 0s 433us/step - loss: 0.4297 - val_loss: 0.1703\n",
      "Epoch 50/100\n",
      "402/402 [==============================] - 0s 457us/step - loss: 0.1252 - val_loss: 0.0906\n",
      "Epoch 51/100\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.0864\n",
      "Epoch 52/100\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0826\n",
      "Epoch 53/100\n",
      "402/402 [==============================] - 0s 955us/step - loss: 0.0880 - val_loss: 0.0755\n",
      "Epoch 54/100\n",
      "402/402 [==============================] - 0s 527us/step - loss: 0.0741 - val_loss: 0.0679\n",
      "Epoch 55/100\n",
      "402/402 [==============================] - 0s 600us/step - loss: 0.0696 - val_loss: 0.0632\n",
      "Epoch 56/100\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0670 - val_loss: 0.0630\n",
      "Epoch 57/100\n",
      "402/402 [==============================] - 0s 562us/step - loss: 0.0652 - val_loss: 0.0573\n",
      "Epoch 58/100\n",
      "402/402 [==============================] - 0s 708us/step - loss: 0.0635 - val_loss: 0.0578\n",
      "Epoch 59/100\n",
      "402/402 [==============================] - 0s 637us/step - loss: 0.0619 - val_loss: 0.0563\n",
      "Epoch 60/100\n",
      "402/402 [==============================] - 0s 704us/step - loss: 0.0609 - val_loss: 0.0523\n",
      "Epoch 61/100\n",
      "402/402 [==============================] - 0s 479us/step - loss: 0.0592 - val_loss: 0.0524\n",
      "Epoch 62/100\n",
      "402/402 [==============================] - 0s 565us/step - loss: 0.0580 - val_loss: 0.0500\n",
      "Epoch 63/100\n",
      "402/402 [==============================] - 0s 536us/step - loss: 0.0569 - val_loss: 0.0490\n",
      "Epoch 64/100\n",
      "402/402 [==============================] - 0s 542us/step - loss: 0.0559 - val_loss: 0.0486\n",
      "Epoch 65/100\n",
      "402/402 [==============================] - 0s 494us/step - loss: 0.0550 - val_loss: 0.0512\n",
      "Epoch 66/100\n",
      "402/402 [==============================] - 0s 478us/step - loss: 0.0542 - val_loss: 0.0462\n",
      "Epoch 67/100\n",
      "402/402 [==============================] - 0s 558us/step - loss: 0.0534 - val_loss: 0.0470\n",
      "Epoch 68/100\n",
      "402/402 [==============================] - 0s 501us/step - loss: 0.0528 - val_loss: 0.0472\n",
      "Epoch 69/100\n",
      "402/402 [==============================] - 0s 543us/step - loss: 0.0523 - val_loss: 0.0450\n",
      "Epoch 70/100\n",
      "402/402 [==============================] - 0s 474us/step - loss: 0.0520 - val_loss: 0.0444\n",
      "Epoch 71/100\n",
      "402/402 [==============================] - 0s 505us/step - loss: 0.0517 - val_loss: 0.0441\n",
      "Epoch 72/100\n",
      "402/402 [==============================] - 0s 558us/step - loss: 0.0513 - val_loss: 0.0474\n",
      "Epoch 73/100\n",
      "402/402 [==============================] - 0s 513us/step - loss: 0.0509 - val_loss: 0.0429\n",
      "Epoch 74/100\n",
      "402/402 [==============================] - 0s 605us/step - loss: 0.0505 - val_loss: 0.0456\n",
      "Epoch 75/100\n",
      "402/402 [==============================] - 0s 488us/step - loss: 0.0505 - val_loss: 0.0417\n",
      "Epoch 76/100\n",
      "402/402 [==============================] - 0s 597us/step - loss: 0.0501 - val_loss: 0.0432\n",
      "Epoch 77/100\n",
      "402/402 [==============================] - 0s 533us/step - loss: 0.0498 - val_loss: 0.0403\n",
      "Epoch 78/100\n",
      "402/402 [==============================] - 0s 576us/step - loss: 0.0495 - val_loss: 0.0421\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 491us/step - loss: 0.0493 - val_loss: 0.0405\n",
      "Epoch 80/100\n",
      "402/402 [==============================] - 0s 450us/step - loss: 0.0490 - val_loss: 0.0425\n",
      "Epoch 81/100\n",
      "402/402 [==============================] - 0s 481us/step - loss: 0.0488 - val_loss: 0.0398\n",
      "Epoch 82/100\n",
      "402/402 [==============================] - 0s 500us/step - loss: 0.0485 - val_loss: 0.0433\n",
      "Epoch 83/100\n",
      "402/402 [==============================] - 0s 473us/step - loss: 0.0486 - val_loss: 0.0403\n",
      "Epoch 84/100\n",
      "402/402 [==============================] - 0s 470us/step - loss: 0.0483 - val_loss: 0.0390\n",
      "Epoch 85/100\n",
      "402/402 [==============================] - 0s 474us/step - loss: 0.0485 - val_loss: 0.0399\n",
      "Epoch 86/100\n",
      "402/402 [==============================] - 0s 489us/step - loss: 0.0479 - val_loss: 0.0386\n",
      "Epoch 87/100\n",
      "402/402 [==============================] - 0s 435us/step - loss: 0.0476 - val_loss: 0.0428\n",
      "Epoch 88/100\n",
      "402/402 [==============================] - 0s 475us/step - loss: 0.0479 - val_loss: 0.0395\n",
      "Epoch 89/100\n",
      "402/402 [==============================] - 0s 493us/step - loss: 0.0475 - val_loss: 0.0408\n",
      "Epoch 90/100\n",
      "402/402 [==============================] - 0s 472us/step - loss: 0.0474 - val_loss: 0.0386\n",
      "Epoch 91/100\n",
      "402/402 [==============================] - 0s 518us/step - loss: 0.0471 - val_loss: 0.0385\n",
      "Epoch 92/100\n",
      "402/402 [==============================] - 0s 421us/step - loss: 0.0473 - val_loss: 0.0402\n",
      "Epoch 93/100\n",
      "402/402 [==============================] - 0s 473us/step - loss: 0.0471 - val_loss: 0.0385\n",
      "Epoch 94/100\n",
      "402/402 [==============================] - 0s 466us/step - loss: 0.0469 - val_loss: 0.0405\n",
      "Epoch 95/100\n",
      "402/402 [==============================] - 0s 461us/step - loss: 0.0469 - val_loss: 0.0406\n",
      "Epoch 96/100\n",
      "402/402 [==============================] - 0s 494us/step - loss: 0.0468 - val_loss: 0.0414\n",
      "Epoch 97/100\n",
      "402/402 [==============================] - 0s 493us/step - loss: 0.0467 - val_loss: 0.0374\n",
      "Epoch 98/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.0466 - val_loss: 0.0378\n",
      "Epoch 99/100\n",
      "402/402 [==============================] - 0s 480us/step - loss: 0.0464 - val_loss: 0.0372\n",
      "Epoch 100/100\n",
      "402/402 [==============================] - 0s 518us/step - loss: 0.0465 - val_loss: 0.0398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118838630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88518584  0.44518411  0.8132807  ...,  0.76284951  0.54920781\n",
      "   0.14154467]\n",
      " [ 0.86306655  0.72427297  0.83906728 ...,  0.56884378  0.59413308\n",
      "   0.30957258]\n",
      " [ 0.70966244  0.91874552  0.8665269  ...,  0.61004996  0.14211443\n",
      "   0.1940673 ]\n",
      " ..., \n",
      " [ 0.79226184  0.73697954  0.75915951 ...,  0.39056638  0.73924291\n",
      "   0.65016621]\n",
      " [ 0.71261567  0.59456712  0.69955641 ...,  0.69032276  0.4422529\n",
      "   0.43007767]\n",
      " [ 0.79393643  0.44714832  0.6922946  ...,  0.60178351  0.70207602\n",
      "   0.40644002]]\n"
     ]
    }
   ],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)\n",
    "print(reduced_representation_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "402/402 [==============================] - 0s 685us/step - loss: 0.0466 - val_loss: 0.0370\n",
      "Epoch 2/100\n",
      "402/402 [==============================] - 0s 450us/step - loss: 0.0461 - val_loss: 0.0372\n",
      "Epoch 3/100\n",
      "402/402 [==============================] - 0s 473us/step - loss: 0.0463 - val_loss: 0.0371\n",
      "Epoch 4/100\n",
      "402/402 [==============================] - 0s 449us/step - loss: 0.0460 - val_loss: 0.0368\n",
      "Epoch 5/100\n",
      "402/402 [==============================] - 0s 477us/step - loss: 0.0459 - val_loss: 0.0387\n",
      "Epoch 6/100\n",
      "402/402 [==============================] - 0s 651us/step - loss: 0.0460 - val_loss: 0.0365\n",
      "Epoch 7/100\n",
      "402/402 [==============================] - 0s 511us/step - loss: 0.0456 - val_loss: 0.0376\n",
      "Epoch 8/100\n",
      "402/402 [==============================] - 0s 463us/step - loss: 0.0457 - val_loss: 0.0386\n",
      "Epoch 9/100\n",
      "402/402 [==============================] - 0s 433us/step - loss: 0.0459 - val_loss: 0.0368\n",
      "Epoch 10/100\n",
      "402/402 [==============================] - 0s 661us/step - loss: 0.0457 - val_loss: 0.0363\n",
      "Epoch 11/100\n",
      "402/402 [==============================] - 0s 554us/step - loss: 0.0458 - val_loss: 0.0365\n",
      "Epoch 12/100\n",
      "402/402 [==============================] - 0s 502us/step - loss: 0.0455 - val_loss: 0.0370\n",
      "Epoch 13/100\n",
      "402/402 [==============================] - 0s 496us/step - loss: 0.0455 - val_loss: 0.0357\n",
      "Epoch 14/100\n",
      "402/402 [==============================] - 0s 481us/step - loss: 0.0455 - val_loss: 0.0382\n",
      "Epoch 15/100\n",
      "402/402 [==============================] - 0s 519us/step - loss: 0.0452 - val_loss: 0.0360\n",
      "Epoch 16/100\n",
      "402/402 [==============================] - 0s 480us/step - loss: 0.0455 - val_loss: 0.0361\n",
      "Epoch 17/100\n",
      "402/402 [==============================] - 0s 550us/step - loss: 0.0451 - val_loss: 0.0396\n",
      "Epoch 18/100\n",
      "402/402 [==============================] - 0s 452us/step - loss: 0.0452 - val_loss: 0.0359\n",
      "Epoch 19/100\n",
      "402/402 [==============================] - 0s 471us/step - loss: 0.0453 - val_loss: 0.0362\n",
      "Epoch 20/100\n",
      "402/402 [==============================] - 0s 482us/step - loss: 0.0451 - val_loss: 0.0369\n",
      "Epoch 21/100\n",
      "402/402 [==============================] - 0s 480us/step - loss: 0.0449 - val_loss: 0.0354\n",
      "Epoch 22/100\n",
      "402/402 [==============================] - 0s 610us/step - loss: 0.0451 - val_loss: 0.0364\n",
      "Epoch 23/100\n",
      "402/402 [==============================] - 0s 634us/step - loss: 0.0449 - val_loss: 0.0386\n",
      "Epoch 24/100\n",
      "402/402 [==============================] - 0s 799us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 25/100\n",
      "402/402 [==============================] - 0s 536us/step - loss: 0.0451 - val_loss: 0.0354\n",
      "Epoch 26/100\n",
      "402/402 [==============================] - 0s 531us/step - loss: 0.0448 - val_loss: 0.0363\n",
      "Epoch 27/100\n",
      "402/402 [==============================] - 0s 704us/step - loss: 0.0448 - val_loss: 0.0352\n",
      "Epoch 28/100\n",
      "402/402 [==============================] - 0s 478us/step - loss: 0.0446 - val_loss: 0.0353\n",
      "Epoch 29/100\n",
      "402/402 [==============================] - 0s 412us/step - loss: 0.0449 - val_loss: 0.0348\n",
      "Epoch 30/100\n",
      "402/402 [==============================] - 0s 462us/step - loss: 0.0445 - val_loss: 0.0363\n",
      "Epoch 31/100\n",
      "402/402 [==============================] - 0s 478us/step - loss: 0.0444 - val_loss: 0.0400\n",
      "Epoch 32/100\n",
      "402/402 [==============================] - 0s 466us/step - loss: 0.0446 - val_loss: 0.0355\n",
      "Epoch 33/100\n",
      "402/402 [==============================] - 0s 472us/step - loss: 0.0444 - val_loss: 0.0348\n",
      "Epoch 34/100\n",
      "402/402 [==============================] - 0s 477us/step - loss: 0.0442 - val_loss: 0.0350\n",
      "Epoch 35/100\n",
      "402/402 [==============================] - 0s 482us/step - loss: 0.0443 - val_loss: 0.0347\n",
      "Epoch 36/100\n",
      "402/402 [==============================] - 0s 479us/step - loss: 0.0442 - val_loss: 0.0345\n",
      "Epoch 37/100\n",
      "402/402 [==============================] - 0s 459us/step - loss: 0.0440 - val_loss: 0.0356\n",
      "Epoch 38/100\n",
      "402/402 [==============================] - 0s 452us/step - loss: 0.0440 - val_loss: 0.0361\n",
      "Epoch 39/100\n",
      "402/402 [==============================] - 0s 459us/step - loss: 0.0441 - val_loss: 0.0358\n",
      "Epoch 40/100\n",
      "402/402 [==============================] - 0s 456us/step - loss: 0.0439 - val_loss: 0.0342\n",
      "Epoch 41/100\n",
      "402/402 [==============================] - 0s 454us/step - loss: 0.0439 - val_loss: 0.0367\n",
      "Epoch 42/100\n",
      "402/402 [==============================] - 0s 452us/step - loss: 0.0438 - val_loss: 0.0351\n",
      "Epoch 43/100\n",
      "402/402 [==============================] - 0s 462us/step - loss: 0.0438 - val_loss: 0.0355\n",
      "Epoch 44/100\n",
      "402/402 [==============================] - 0s 442us/step - loss: 0.0438 - val_loss: 0.0343\n",
      "Epoch 45/100\n",
      "402/402 [==============================] - 0s 413us/step - loss: 0.0437 - val_loss: 0.0358\n",
      "Epoch 46/100\n",
      "402/402 [==============================] - 0s 453us/step - loss: 0.0436 - val_loss: 0.0381\n",
      "Epoch 47/100\n",
      "402/402 [==============================] - 0s 454us/step - loss: 0.0436 - val_loss: 0.0343\n",
      "Epoch 48/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.0437 - val_loss: 0.0340\n",
      "Epoch 49/100\n",
      "402/402 [==============================] - 0s 479us/step - loss: 0.0433 - val_loss: 0.0340\n",
      "Epoch 50/100\n",
      "402/402 [==============================] - 0s 472us/step - loss: 0.0435 - val_loss: 0.0338\n",
      "Epoch 51/100\n",
      "402/402 [==============================] - 0s 451us/step - loss: 0.0432 - val_loss: 0.0345\n",
      "Epoch 52/100\n",
      "402/402 [==============================] - 0s 457us/step - loss: 0.0433 - val_loss: 0.0342\n",
      "Epoch 53/100\n",
      "402/402 [==============================] - 0s 449us/step - loss: 0.0433 - val_loss: 0.0343\n",
      "Epoch 54/100\n",
      "402/402 [==============================] - 0s 427us/step - loss: 0.0433 - val_loss: 0.0342\n",
      "Epoch 55/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.0430 - val_loss: 0.0340\n",
      "Epoch 56/100\n",
      "402/402 [==============================] - 0s 430us/step - loss: 0.0432 - val_loss: 0.0431\n",
      "Epoch 57/100\n",
      "402/402 [==============================] - 0s 444us/step - loss: 0.0431 - val_loss: 0.0341\n",
      "Epoch 58/100\n",
      "402/402 [==============================] - 0s 473us/step - loss: 0.0430 - val_loss: 0.0393\n",
      "Epoch 59/100\n",
      "402/402 [==============================] - 0s 429us/step - loss: 0.0429 - val_loss: 0.0372\n",
      "Epoch 60/100\n",
      "402/402 [==============================] - 0s 428us/step - loss: 0.0430 - val_loss: 0.0335\n",
      "Epoch 61/100\n",
      "402/402 [==============================] - 0s 445us/step - loss: 0.0428 - val_loss: 0.0429\n",
      "Epoch 62/100\n",
      "402/402 [==============================] - 0s 451us/step - loss: 0.0428 - val_loss: 0.0350\n",
      "Epoch 63/100\n",
      "402/402 [==============================] - 0s 454us/step - loss: 0.0430 - val_loss: 0.0334\n",
      "Epoch 64/100\n",
      "402/402 [==============================] - 0s 460us/step - loss: 0.0429 - val_loss: 0.0342\n",
      "Epoch 65/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.0427 - val_loss: 0.0394\n",
      "Epoch 66/100\n",
      "402/402 [==============================] - 0s 453us/step - loss: 0.0429 - val_loss: 0.0346\n",
      "Epoch 67/100\n",
      "402/402 [==============================] - 0s 452us/step - loss: 0.0427 - val_loss: 0.0338\n",
      "Epoch 68/100\n",
      "402/402 [==============================] - 0s 430us/step - loss: 0.0427 - val_loss: 0.0346\n",
      "Epoch 69/100\n",
      "402/402 [==============================] - 0s 421us/step - loss: 0.0427 - val_loss: 0.0336\n",
      "Epoch 70/100\n",
      "402/402 [==============================] - 0s 447us/step - loss: 0.0427 - val_loss: 0.0332\n",
      "Epoch 71/100\n",
      "402/402 [==============================] - 0s 425us/step - loss: 0.0426 - val_loss: 0.0341\n",
      "Epoch 72/100\n",
      "402/402 [==============================] - 0s 460us/step - loss: 0.0425 - val_loss: 0.0348\n",
      "Epoch 73/100\n",
      "402/402 [==============================] - 0s 427us/step - loss: 0.0425 - val_loss: 0.0337\n",
      "Epoch 74/100\n",
      "402/402 [==============================] - 0s 421us/step - loss: 0.0425 - val_loss: 0.0373\n",
      "Epoch 75/100\n",
      "402/402 [==============================] - 0s 476us/step - loss: 0.0425 - val_loss: 0.0360\n",
      "Epoch 76/100\n",
      "402/402 [==============================] - 0s 493us/step - loss: 0.0426 - val_loss: 0.0330\n",
      "Epoch 77/100\n",
      "402/402 [==============================] - 0s 508us/step - loss: 0.0425 - val_loss: 0.0342\n",
      "Epoch 78/100\n",
      "402/402 [==============================] - 0s 386us/step - loss: 0.0424 - val_loss: 0.0334\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 413us/step - loss: 0.0424 - val_loss: 0.0345\n",
      "Epoch 80/100\n",
      "402/402 [==============================] - 0s 429us/step - loss: 0.0425 - val_loss: 0.0335\n",
      "Epoch 81/100\n",
      "402/402 [==============================] - 0s 413us/step - loss: 0.0424 - val_loss: 0.0421\n",
      "Epoch 82/100\n",
      "402/402 [==============================] - 0s 480us/step - loss: 0.0423 - val_loss: 0.0337\n",
      "Epoch 83/100\n",
      "402/402 [==============================] - 0s 418us/step - loss: 0.0423 - val_loss: 0.0353\n",
      "Epoch 84/100\n",
      "402/402 [==============================] - 0s 439us/step - loss: 0.0423 - val_loss: 0.0334\n",
      "Epoch 85/100\n",
      "402/402 [==============================] - 0s 474us/step - loss: 0.0423 - val_loss: 0.0348\n",
      "Epoch 86/100\n",
      "402/402 [==============================] - 0s 462us/step - loss: 0.0422 - val_loss: 0.0345\n",
      "Epoch 87/100\n",
      "402/402 [==============================] - 0s 458us/step - loss: 0.0423 - val_loss: 0.0334\n",
      "Epoch 88/100\n",
      "402/402 [==============================] - 0s 463us/step - loss: 0.0423 - val_loss: 0.0338\n",
      "Epoch 89/100\n",
      "402/402 [==============================] - 0s 435us/step - loss: 0.0421 - val_loss: 0.0357\n",
      "Epoch 90/100\n",
      "402/402 [==============================] - 0s 416us/step - loss: 0.0422 - val_loss: 0.0338\n",
      "Epoch 91/100\n",
      "402/402 [==============================] - 0s 410us/step - loss: 0.0422 - val_loss: 0.0336\n",
      "Epoch 92/100\n",
      "402/402 [==============================] - 0s 425us/step - loss: 0.0422 - val_loss: 0.0327\n",
      "Epoch 93/100\n",
      "402/402 [==============================] - 0s 431us/step - loss: 0.0420 - val_loss: 0.0341\n",
      "Epoch 94/100\n",
      "402/402 [==============================] - 0s 422us/step - loss: 0.0421 - val_loss: 0.0340\n",
      "Epoch 95/100\n",
      "402/402 [==============================] - 0s 547us/step - loss: 0.0421 - val_loss: 0.0342\n",
      "Epoch 96/100\n",
      "402/402 [==============================] - 0s 567us/step - loss: 0.0422 - val_loss: 0.0351\n",
      "Epoch 97/100\n",
      "402/402 [==============================] - 0s 431us/step - loss: 0.0421 - val_loss: 0.0332\n",
      "Epoch 98/100\n",
      "402/402 [==============================] - 0s 432us/step - loss: 0.0420 - val_loss: 0.0343\n",
      "Epoch 99/100\n",
      "402/402 [==============================] - 0s 400us/step - loss: 0.0421 - val_loss: 0.0336\n",
      "Epoch 100/100\n",
      "402/402 [==============================] - 0s 460us/step - loss: 0.0419 - val_loss: 0.0339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118b524e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss\n",
    "\n",
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2_my = Dense(1, activation='linear')(encoder_my.output)\n",
    "newmodel_my = Model(encoder_my.input,out2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newmodel_my.compile(loss='mean_squared_error', optimizer='rmsprop', \n",
    "          metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 300us/step - loss: 7.7205 - acc: 0.0044 - val_loss: 6.0354 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 43us/step - loss: 5.4119 - acc: 0.0156 - val_loss: 4.8308 - val_acc: 0.0129\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 4.4001 - acc: 0.0222 - val_loss: 4.0796 - val_acc: 0.0386\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 3.7394 - acc: 0.0667 - val_loss: 3.5347 - val_acc: 0.0815\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 3.2516 - acc: 0.0800 - val_loss: 3.1120 - val_acc: 0.1073\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 2.8735 - acc: 0.1044 - val_loss: 2.7744 - val_acc: 0.1330\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 2.5696 - acc: 0.1289 - val_loss: 2.4986 - val_acc: 0.1416\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 2.3157 - acc: 0.1489 - val_loss: 2.2594 - val_acc: 0.1717\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.2653 - acc: 0.195 - 0s 44us/step - loss: 2.0969 - acc: 0.1622 - val_loss: 2.0576 - val_acc: 0.1931\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 1.9105 - acc: 0.1667 - val_loss: 1.8827 - val_acc: 0.2060\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 1.7487 - acc: 0.1667 - val_loss: 1.7317 - val_acc: 0.2103\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 1.6092 - acc: 0.1822 - val_loss: 1.6015 - val_acc: 0.2275\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 1.4888 - acc: 0.2156 - val_loss: 1.4892 - val_acc: 0.2704\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 1.3831 - acc: 0.2222 - val_loss: 1.3903 - val_acc: 0.2833\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 1.2911 - acc: 0.2267 - val_loss: 1.3048 - val_acc: 0.2833\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 1.2114 - acc: 0.2289 - val_loss: 1.2286 - val_acc: 0.2833\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 1.1409 - acc: 0.2289 - val_loss: 1.1631 - val_acc: 0.2833\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 44us/step - loss: 1.0793 - acc: 0.2289 - val_loss: 1.1050 - val_acc: 0.2833\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 1.0243 - acc: 0.2289 - val_loss: 1.0522 - val_acc: 0.2833\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.9732 - acc: 0.2289 - val_loss: 1.0025 - val_acc: 0.2833\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.9237 - acc: 0.2289 - val_loss: 0.9513 - val_acc: 0.2833\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 0.8706 - acc: 0.2289 - val_loss: 0.8919 - val_acc: 0.2833\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 0.8029 - acc: 0.2289 - val_loss: 0.8258 - val_acc: 0.2833\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.7451 - acc: 0.2311 - val_loss: 0.7801 - val_acc: 0.3133\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 0.7052 - acc: 0.3089 - val_loss: 0.7434 - val_acc: 0.4077\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.6727 - acc: 0.4089 - val_loss: 0.7152 - val_acc: 0.4421\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 68us/step - loss: 0.6462 - acc: 0.4622 - val_loss: 0.6917 - val_acc: 0.4678\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 0.6242 - acc: 0.5267 - val_loss: 0.6712 - val_acc: 0.5966\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.6044 - acc: 0.6356 - val_loss: 0.6509 - val_acc: 0.5837\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.5860 - acc: 0.6356 - val_loss: 0.6348 - val_acc: 0.6009\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 0.5707 - acc: 0.6311 - val_loss: 0.6207 - val_acc: 0.5579\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.5574 - acc: 0.6111 - val_loss: 0.6080 - val_acc: 0.5365\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.5448 - acc: 0.6089 - val_loss: 0.5954 - val_acc: 0.5322\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 0.5324 - acc: 0.6089 - val_loss: 0.5845 - val_acc: 0.5322\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.5212 - acc: 0.6067 - val_loss: 0.5735 - val_acc: 0.5451\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.5101 - acc: 0.6089 - val_loss: 0.5619 - val_acc: 0.5622\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 77us/step - loss: 0.4991 - acc: 0.6067 - val_loss: 0.5510 - val_acc: 0.5751\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.4876 - acc: 0.6178 - val_loss: 0.5396 - val_acc: 0.5665\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 0.4764 - acc: 0.6200 - val_loss: 0.5308 - val_acc: 0.5665\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 0.4658 - acc: 0.6178 - val_loss: 0.5205 - val_acc: 0.5622\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 0.4553 - acc: 0.6222 - val_loss: 0.5124 - val_acc: 0.5579\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.4454 - acc: 0.6244 - val_loss: 0.5055 - val_acc: 0.5665\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.4356 - acc: 0.6311 - val_loss: 0.4955 - val_acc: 0.5665\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.4257 - acc: 0.6222 - val_loss: 0.4907 - val_acc: 0.5665\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 67us/step - loss: 0.4163 - acc: 0.6267 - val_loss: 0.4842 - val_acc: 0.5708\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 77us/step - loss: 0.4060 - acc: 0.6289 - val_loss: 0.4786 - val_acc: 0.5665\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 88us/step - loss: 0.3960 - acc: 0.6378 - val_loss: 0.4684 - val_acc: 0.5622\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.3855 - acc: 0.6400 - val_loss: 0.4612 - val_acc: 0.5665\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 65us/step - loss: 0.3782 - acc: 0.6467 - val_loss: 0.4573 - val_acc: 0.5665\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 0.3692 - acc: 0.6511 - val_loss: 0.4520 - val_acc: 0.5665\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 0.3640 - acc: 0.6533 - val_loss: 0.4522 - val_acc: 0.5708\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 68us/step - loss: 0.3579 - acc: 0.6578 - val_loss: 0.4432 - val_acc: 0.5665\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 0.3498 - acc: 0.6556 - val_loss: 0.4513 - val_acc: 0.5794\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 63us/step - loss: 0.3467 - acc: 0.6711 - val_loss: 0.4330 - val_acc: 0.5751\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.3366 - acc: 0.6644 - val_loss: 0.4291 - val_acc: 0.5708\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 0.3337 - acc: 0.6600 - val_loss: 0.4210 - val_acc: 0.5665\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 0.3251 - acc: 0.6778 - val_loss: 0.4224 - val_acc: 0.5966\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 0.3233 - acc: 0.6667 - val_loss: 0.4173 - val_acc: 0.5880\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.3145 - acc: 0.6778 - val_loss: 0.4139 - val_acc: 0.5880\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 0.3106 - acc: 0.6689 - val_loss: 0.4040 - val_acc: 0.5966\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 52us/step - loss: 0.3047 - acc: 0.6756 - val_loss: 0.3967 - val_acc: 0.6009\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 0.2978 - acc: 0.6778 - val_loss: 0.3957 - val_acc: 0.6009\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 0.2942 - acc: 0.6867 - val_loss: 0.3931 - val_acc: 0.6009\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 70us/step - loss: 0.2943 - acc: 0.7044 - val_loss: 0.3843 - val_acc: 0.6094\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 0.2823 - acc: 0.6978 - val_loss: 0.3800 - val_acc: 0.5923\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 0.2797 - acc: 0.6933 - val_loss: 0.3836 - val_acc: 0.6009\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.2785 - acc: 0.6933 - val_loss: 0.3731 - val_acc: 0.6094\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.2738 - acc: 0.6956 - val_loss: 0.3710 - val_acc: 0.6223\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 0.2655 - acc: 0.6956 - val_loss: 0.3674 - val_acc: 0.6137\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.2608 - acc: 0.7133 - val_loss: 0.3660 - val_acc: 0.6094\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 0.2565 - acc: 0.7156 - val_loss: 0.3666 - val_acc: 0.6137\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 42us/step - loss: 0.2521 - acc: 0.7111 - val_loss: 0.3537 - val_acc: 0.6309\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 44us/step - loss: 0.2464 - acc: 0.7178 - val_loss: 0.3497 - val_acc: 0.6309\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 44us/step - loss: 0.2441 - acc: 0.7178 - val_loss: 0.3531 - val_acc: 0.6137\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 43us/step - loss: 0.2373 - acc: 0.7178 - val_loss: 0.3580 - val_acc: 0.6567\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.2473 - acc: 0.7156 - val_loss: 0.3409 - val_acc: 0.6652\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.2317 - acc: 0.7378 - val_loss: 0.3355 - val_acc: 0.6695\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 74us/step - loss: 0.2264 - acc: 0.7378 - val_loss: 0.3367 - val_acc: 0.6395\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.2235 - acc: 0.7289 - val_loss: 0.3295 - val_acc: 0.6824\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2249 - acc: 0.7289 - val_loss: 0.3242 - val_acc: 0.6824\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 77us/step - loss: 0.2154 - acc: 0.7511 - val_loss: 0.3282 - val_acc: 0.6438\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 74us/step - loss: 0.2119 - acc: 0.7333 - val_loss: 0.3161 - val_acc: 0.6824\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.2094 - acc: 0.7622 - val_loss: 0.3221 - val_acc: 0.6953\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 0.2066 - acc: 0.7422 - val_loss: 0.3097 - val_acc: 0.6867\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 40us/step - loss: 0.1992 - acc: 0.7622 - val_loss: 0.3063 - val_acc: 0.6781\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 0.1959 - acc: 0.7844 - val_loss: 0.3122 - val_acc: 0.6781\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 39us/step - loss: 0.1929 - acc: 0.7644 - val_loss: 0.2984 - val_acc: 0.6996\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 0.2011 - acc: 0.7711 - val_loss: 0.2957 - val_acc: 0.6953\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 43us/step - loss: 0.1894 - acc: 0.7778 - val_loss: 0.3004 - val_acc: 0.6867\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 40us/step - loss: 0.1829 - acc: 0.7867 - val_loss: 0.2949 - val_acc: 0.7039\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 45us/step - loss: 0.1940 - acc: 0.7844 - val_loss: 0.2877 - val_acc: 0.6953\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 45us/step - loss: 0.1771 - acc: 0.7956 - val_loss: 0.2841 - val_acc: 0.6996\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 0.1731 - acc: 0.8022 - val_loss: 0.2862 - val_acc: 0.7082\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 44us/step - loss: 0.1784 - acc: 0.7844 - val_loss: 0.2899 - val_acc: 0.6910\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.1871 - acc: 0.7867 - val_loss: 0.2737 - val_acc: 0.7039\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 0.1665 - acc: 0.8067 - val_loss: 0.2819 - val_acc: 0.6867\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.1680 - acc: 0.8133 - val_loss: 0.2710 - val_acc: 0.6910\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.1631 - acc: 0.8089 - val_loss: 0.2840 - val_acc: 0.7124\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 0.1749 - acc: 0.7911 - val_loss: 0.2665 - val_acc: 0.7210\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 42us/step - loss: 0.1690 - acc: 0.8111 - val_loss: 0.2580 - val_acc: 0.7124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11633f278>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel_my.fit(X_train_my, Y_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, Y_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 0s 58us/step\n",
      "0.258042764246\n",
      "233/233 [==============================] - 0s 48us/step\n",
      "[ 2.44855976  3.18597341  1.88801622  2.48548508  2.1656785   3.10200214\n",
      "  2.86757183  3.05590105  3.35316634  2.50146008  3.17879677  2.98581767\n",
      "  3.12786603  3.0231421   2.92873144  3.10971808  3.0133462   2.01866317\n",
      "  3.4212575   3.35316634  2.97087049  2.76094007  2.96481752  2.31010437\n",
      "  2.22806811  3.29219365  3.37456846  2.96481752  3.60140395  2.96481752\n",
      "  2.71483088  1.92142689  3.04480338  2.31010437  3.10990715  3.03814507\n",
      "  2.79737926  2.90098667  3.59944606  3.19175339  2.61034322  2.69785166\n",
      "  2.1393137   3.11223364  2.53577518  2.31010437  3.12786603  2.38901949\n",
      "  3.47090268  3.26427031  3.05750871  2.92413592  3.35316634  2.29372382\n",
      "  3.59166312  2.75493288  1.99140978  3.55735135  2.83105636  3.32114482\n",
      "  2.90242887  2.35701013  2.93755579  3.0957551   3.0532372   3.12786603\n",
      "  2.96481752  2.91923237  3.36113739  3.15727639  2.78172398  3.1884625\n",
      "  3.62642241  2.83380342  3.29251885  2.11214995  3.09568882  3.18520832\n",
      "  2.88877869  3.20545912  3.01108599  2.77664423  2.81814241  2.26854157\n",
      "  2.46220326  3.53378749  3.52343678  2.83611393  2.40702009  2.96481752\n",
      "  2.46524167  2.90384054  3.68422174  3.07973742  2.57386613  3.58524489\n",
      "  2.7815783   2.94186115  3.2241044   2.7219944   3.20311356  2.31010437\n",
      "  2.52269721  2.86160469  3.31096506  2.82677841  2.77179003  2.15914106\n",
      "  2.65284085  2.31010437  2.85224748  2.57281542  1.7792604   2.37909079\n",
      "  2.24464035  3.35897708  3.46483254  2.41459537  1.90931952  2.94018173\n",
      "  2.96481752  2.26603079  2.98079395  3.42058277  3.35316634  2.9196136\n",
      "  3.17949343  3.13299441  2.87721586  2.30114746  3.53448868  2.446733\n",
      "  2.09311914  3.38850665  2.26247621  2.31010437  3.02339077  3.46077251\n",
      "  2.96481752  2.31200194  2.31010437  2.85514998  2.85682631  2.21945453\n",
      "  2.14740443  3.05504036  2.48555493  3.64183807  3.54276538  2.18276072\n",
      "  2.96481752  2.24012423  3.34511685  2.06710339  2.83025289  2.70352817\n",
      "  2.71790862  2.64016271  2.77711558  2.67812848  3.1554985   2.97254705\n",
      "  2.61479497  2.92710018  2.62914944  3.1471076   2.96481752  3.35316634\n",
      "  2.77863979  2.96481752  2.18827128  2.96481752  3.63719225  3.17447495\n",
      "  2.99902725  3.35316634  1.99509799  2.31010437  3.61507249  2.800951\n",
      "  2.88870406  2.7789278   2.8796761   3.37137461  2.96481752  3.04412818\n",
      "  3.54626441  3.13486195  2.2419796   2.35130548  3.452492    2.91880822\n",
      "  3.14756513  2.5391376   3.70081496  2.52488303  2.96481752  3.05748129\n",
      "  2.99473739  2.68463635  2.59653902  3.07859659  2.24624991  3.61188698\n",
      "  2.14312601  2.79408741  3.0343883   2.70907831  2.81070375  3.341326\n",
      "  3.43384075  3.35316634  2.99023342  3.27480173  3.3332386   2.17299938\n",
      "  2.61034369  2.49096704  2.9023006   3.42357063  2.96481752  2.61006379\n",
      "  3.35316634  3.52383685  1.44204068  3.25504971  3.33691454  3.29075527\n",
      "  2.40669537  2.90940022  2.44887471  2.50228405  3.27427053]\n",
      "233/233 [==============================] - 0s 74us/step\n",
      "[ 2.  3.  2.  2.  2.  3.  3.  3.  4.  3.  3.  3.  3.  3.  3.  3.  3.  2.\n",
      "  4.  4.  2.  3.  3.  2.  2.  3.  3.  3.  4.  3.  3.  2.  2.  2.  3.  5.\n",
      "  2.  3.  3.  3.  3.  2.  2.  3.  2.  2.  3.  3.  3.  3.  4.  3.  4.  2.\n",
      "  4.  2.  2.  5.  3.  3.  3.  2.  3.  4.  3.  3.  3.  4.  3.  3.  3.  3.\n",
      "  5.  3.  3.  2.  4.  3.  3.  3.  3.  3.  3.  2.  2.  4.  5.  3.  3.  3.\n",
      "  3.  3.  5.  3.  3.  4.  3.  3.  3.  2.  3.  2.  2.  3.  4.  3.  3.  2.\n",
      "  2.  2.  3.  2.  2.  2.  2.  3.  3.  2.  2.  2.  3.  2.  3.  4.  4.  3.\n",
      "  3.  3.  3.  2.  3.  2.  2.  4.  2.  2.  4.  3.  3.  2.  2.  2.  2.  2.\n",
      "  3.  3.  2.  4.  4.  2.  3.  2.  3.  3.  3.  3.  3.  2.  3.  3.  3.  3.\n",
      "  2.  4.  3.  4.  3.  4.  3.  3.  2.  3.  5.  3.  3.  4.  2.  2.  3.  3.\n",
      "  3.  2.  3.  4.  3.  4.  3.  4.  2.  2.  4.  3.  3.  2.  4.  3.  3.  4.\n",
      "  3.  3.  2.  3.  2.  4.  1.  4.  3.  2.  3.  3.  3.  4.  2.  3.  3.  2.\n",
      "  3.  2.  3.  4.  3.  3.  4.  4.  1.  3.  3.  3.  3.  4.  3.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "#print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(newmodel_my.predict(X_test_my, verbose=1).flatten(), Y_test_my)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "#print('Rounded')\n",
    "#print(np.around(newmodel_my.predict(X_test_my, verbose=1).flatten(),decimals=0))\n",
    "\n",
    "scores_my = newmodel_my.evaluate(X_test_my, Y_test_my, verbose=1) \n",
    "print(y_test_my)\n",
    "\n",
    "#print(\"Accuracy: \", scores_my[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
