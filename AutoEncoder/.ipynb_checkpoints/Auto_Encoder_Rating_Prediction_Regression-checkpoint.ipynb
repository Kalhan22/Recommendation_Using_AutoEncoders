{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "from tensorflow.python.ops.variables import trainable_variables\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train_my = genfromtxt('../UserData/655/trainX_655.csv', delimiter=',')\n",
    "y_train_my = genfromtxt('../UserData/655/trainY_655.csv', delimiter=',')\n",
    "X_test_my = genfromtxt('../UserData/655/testX_655.csv', delimiter=',')\n",
    "y_test_my = genfromtxt('../UserData/655/testY_655.csv', delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train_my = X_train_my.astype('float32') \n",
    "X_train_my = X_train_my.astype('float32')\n",
    "print(X_train_my.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_my = y_train_my\n",
    "\n",
    "Y_test_my = y_test_my\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_img_my = Input(shape=(20,))\n",
    "\n",
    "print(input_img_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Relu:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_my = Dense(20, activation='relu')(input_img_my)\n",
    "print(x_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded1_my = Dense(15, activation='relu')(x_my)\n",
    "encoded2_my = Dense(12, activation='relu')(encoded1_my)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_my = Dense(10, activation='relu')(encoded2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded2_my = Dense(12, activation='relu')(y_my)\n",
    "decoded1_my = Dense(15, activation='relu')(decoded2_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_my = Dense(20, activation='relu')(decoded1_my)\n",
    "autoencoder_my = Model(input_img_my, z_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x10f0af940>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "print(encoder_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 20)\n",
      "(450, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_my.shape)\n",
    "\n",
    "print(X_train_my.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...,  0.          0.          0.60000002]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.60000002]\n",
      " [ 0.60000002  0.          0.80000001 ...,  0.          0.80000001\n",
      "   0.40000001]\n",
      " ..., \n",
      " [ 0.          0.          0.60000002 ...,  0.          0.          0.60000002]\n",
      " [ 0.60000002  0.          0.60000002 ...,  0.          0.80000001\n",
      "   0.60000002]\n",
      " [ 0.2         0.          0.2        ...,  0.          0.          0.40000001]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 674us/step - loss: 0.1771 - val_loss: 0.1556\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 510us/step - loss: 0.1578 - val_loss: 0.1461\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 459us/step - loss: 0.1503 - val_loss: 0.1411\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 457us/step - loss: 0.1465 - val_loss: 0.1382\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 498us/step - loss: 0.1445 - val_loss: 0.1365\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 440us/step - loss: 0.1433 - val_loss: 0.1355\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 340us/step - loss: 0.1423 - val_loss: 0.1344\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 391us/step - loss: 0.1412 - val_loss: 0.1333\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 535us/step - loss: 0.1399 - val_loss: 0.1322\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 472us/step - loss: 0.1362 - val_loss: 0.1276\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 379us/step - loss: 0.1336 - val_loss: 0.1259\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 358us/step - loss: 0.1323 - val_loss: 0.1247\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 421us/step - loss: 0.1312 - val_loss: 0.1238\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 380us/step - loss: 0.1302 - val_loss: 0.1228\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 371us/step - loss: 0.1294 - val_loss: 0.1220\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 474us/step - loss: 0.1284 - val_loss: 0.1215\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 445us/step - loss: 0.1275 - val_loss: 0.1207\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.1245 - val_loss: 0.1153\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 463us/step - loss: 0.1199 - val_loss: 0.1138\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 450us/step - loss: 0.1182 - val_loss: 0.1110\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 453us/step - loss: 0.1122 - val_loss: 0.1054\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 509us/step - loss: 0.1091 - val_loss: 0.1037\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.1077 - val_loss: 0.1028\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 450us/step - loss: 0.1067 - val_loss: 0.1019\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 467us/step - loss: 0.1057 - val_loss: 0.1013\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.1051 - val_loss: 0.1006\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 474us/step - loss: 0.1042 - val_loss: 0.1004\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 470us/step - loss: 0.1037 - val_loss: 0.0995\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 463us/step - loss: 0.1031 - val_loss: 0.0989\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 442us/step - loss: 0.1025 - val_loss: 0.0985\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 552us/step - loss: 0.1021 - val_loss: 0.0982\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 495us/step - loss: 0.1015 - val_loss: 0.0976\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 502us/step - loss: 0.1009 - val_loss: 0.0971\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 491us/step - loss: 0.1005 - val_loss: 0.0967\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 464us/step - loss: 0.0998 - val_loss: 0.0968\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 505us/step - loss: 0.0993 - val_loss: 0.0956\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 474us/step - loss: 0.0987 - val_loss: 0.0954\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 482us/step - loss: 0.0980 - val_loss: 0.0950\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 512us/step - loss: 0.0957 - val_loss: 0.0921\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 559us/step - loss: 0.0936 - val_loss: 0.0920\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 512us/step - loss: 0.0929 - val_loss: 0.0911\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 850us/step - loss: 0.0923 - val_loss: 0.0901\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 489us/step - loss: 0.0918 - val_loss: 0.0899\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 454us/step - loss: 0.0915 - val_loss: 0.0897\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 495us/step - loss: 0.0911 - val_loss: 0.0894\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 442us/step - loss: 0.0909 - val_loss: 0.0896\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 459us/step - loss: 0.0907 - val_loss: 0.0893\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 430us/step - loss: 0.0906 - val_loss: 0.0888\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 443us/step - loss: 0.0901 - val_loss: 0.0893\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 447us/step - loss: 0.0902 - val_loss: 0.0887\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.090 - 0s 448us/step - loss: 0.0899 - val_loss: 0.0888\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0897 - val_loss: 0.0884\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 639us/step - loss: 0.0896 - val_loss: 0.0886\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 494us/step - loss: 0.0895 - val_loss: 0.0883\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 643us/step - loss: 0.0894 - val_loss: 0.0882\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 494us/step - loss: 0.0892 - val_loss: 0.0883\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 614us/step - loss: 0.0890 - val_loss: 0.0880\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 458us/step - loss: 0.0891 - val_loss: 0.0874\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 661us/step - loss: 0.0889 - val_loss: 0.0876\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 424us/step - loss: 0.0888 - val_loss: 0.0879\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 428us/step - loss: 0.0886 - val_loss: 0.0876\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 485us/step - loss: 0.0884 - val_loss: 0.0871\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.086 - 0s 446us/step - loss: 0.0884 - val_loss: 0.0871\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 450us/step - loss: 0.0881 - val_loss: 0.0869\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 411us/step - loss: 0.0881 - val_loss: 0.0870\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0878 - val_loss: 0.0864\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 435us/step - loss: 0.0876 - val_loss: 0.0861\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 455us/step - loss: 0.0874 - val_loss: 0.0860\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 428us/step - loss: 0.0872 - val_loss: 0.0858\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 703us/step - loss: 0.0870 - val_loss: 0.0858\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 451us/step - loss: 0.0868 - val_loss: 0.0869\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 696us/step - loss: 0.0866 - val_loss: 0.0854\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 447us/step - loss: 0.0862 - val_loss: 0.0855\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 424us/step - loss: 0.0860 - val_loss: 0.0853\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0859 - val_loss: 0.0847\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 477us/step - loss: 0.0857 - val_loss: 0.0848\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 433us/step - loss: 0.0855 - val_loss: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 447us/step - loss: 0.0854 - val_loss: 0.0850\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 460us/step - loss: 0.0853 - val_loss: 0.0849\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 424us/step - loss: 0.0851 - val_loss: 0.0839\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 441us/step - loss: 0.0851 - val_loss: 0.0837\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 426us/step - loss: 0.0850 - val_loss: 0.0842\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 441us/step - loss: 0.0848 - val_loss: 0.0843\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 456us/step - loss: 0.0849 - val_loss: 0.0841\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 427us/step - loss: 0.0846 - val_loss: 0.0842\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 448us/step - loss: 0.0848 - val_loss: 0.0836\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 435us/step - loss: 0.0845 - val_loss: 0.0837\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 443us/step - loss: 0.0846 - val_loss: 0.0837\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 444us/step - loss: 0.0845 - val_loss: 0.0836\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 434us/step - loss: 0.0845 - val_loss: 0.0833\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 443us/step - loss: 0.0844 - val_loss: 0.0835\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 431us/step - loss: 0.0843 - val_loss: 0.0835\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0843 - val_loss: 0.0834\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 450us/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 442us/step - loss: 0.0842 - val_loss: 0.0833\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 442us/step - loss: 0.0840 - val_loss: 0.0833\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 434us/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0841 - val_loss: 0.0835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f136b38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07869602  0.12038136  0.75527811 ...,  0.90894055  0.39780101\n",
      "   0.47166541]\n",
      " [ 0.29548827  0.66338718  0.62306941 ...,  0.664307    0.66044247\n",
      "   0.89268214]\n",
      " [ 0.13763216  0.14205377  0.83303374 ...,  0.84062904  0.50515819\n",
      "   0.59612274]\n",
      " ..., \n",
      " [ 0.1602651   0.27401492  0.55030435 ...,  0.87293386  0.40295672\n",
      "   0.45872337]\n",
      " [ 0.03419431  0.15104738  0.60516274 ...,  0.91632742  0.49779686\n",
      "   0.75765777]\n",
      " [ 0.06079213  0.03960025  0.73947668 ...,  0.91981602  0.70712626\n",
      "   0.8501606 ]]\n"
     ]
    }
   ],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)\n",
    "print(reduced_representation_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 653us/step - loss: 0.0842 - val_loss: 0.0832\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 439us/step - loss: 0.0841 - val_loss: 0.0835\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 540us/step - loss: 0.0840 - val_loss: 0.0832\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 504us/step - loss: 0.0838 - val_loss: 0.0832\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 615us/step - loss: 0.0838 - val_loss: 0.0838\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 505us/step - loss: 0.0838 - val_loss: 0.0835\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 311us/step - loss: 0.0838 - val_loss: 0.0832\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 505us/step - loss: 0.0836 - val_loss: 0.0842\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 549us/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 448us/step - loss: 0.0836 - val_loss: 0.0833\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 662us/step - loss: 0.0836 - val_loss: 0.0830\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 520us/step - loss: 0.0836 - val_loss: 0.0839\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 796us/step - loss: 0.0835 - val_loss: 0.0830\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 659us/step - loss: 0.0835 - val_loss: 0.0829\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 539us/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 432us/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 462us/step - loss: 0.0833 - val_loss: 0.0830\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 505us/step - loss: 0.0834 - val_loss: 0.0826\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 446us/step - loss: 0.0834 - val_loss: 0.0828\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 440us/step - loss: 0.0834 - val_loss: 0.0829\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 454us/step - loss: 0.0831 - val_loss: 0.0831\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 446us/step - loss: 0.0832 - val_loss: 0.0830\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 452us/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 448us/step - loss: 0.0832 - val_loss: 0.0827\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 441us/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 456us/step - loss: 0.0831 - val_loss: 0.0825\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 439us/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 449us/step - loss: 0.0831 - val_loss: 0.0828\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 445us/step - loss: 0.0831 - val_loss: 0.0830\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 481us/step - loss: 0.0829 - val_loss: 0.0831\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 468us/step - loss: 0.0829 - val_loss: 0.0823\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 456us/step - loss: 0.0829 - val_loss: 0.0829\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 441us/step - loss: 0.0830 - val_loss: 0.0828\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.083 - 0s 455us/step - loss: 0.0829 - val_loss: 0.0825\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 453us/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 449us/step - loss: 0.0828 - val_loss: 0.0825\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 440us/step - loss: 0.0828 - val_loss: 0.0827\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 523us/step - loss: 0.0828 - val_loss: 0.0821ETA: 0s - loss: 0.08\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 468us/step - loss: 0.0828 - val_loss: 0.0823\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 448us/step - loss: 0.0826 - val_loss: 0.0824\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 727us/step - loss: 0.0826 - val_loss: 0.0827\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 672us/step - loss: 0.0827 - val_loss: 0.0825\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 685us/step - loss: 0.0827 - val_loss: 0.0824\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 484us/step - loss: 0.0825 - val_loss: 0.0829\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 482us/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 498us/step - loss: 0.0824 - val_loss: 0.0824\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 525us/step - loss: 0.0825 - val_loss: 0.0820\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 537us/step - loss: 0.0824 - val_loss: 0.0822\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 574us/step - loss: 0.0825 - val_loss: 0.0824\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 756us/step - loss: 0.0825 - val_loss: 0.0824\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 716us/step - loss: 0.0822 - val_loss: 0.0825\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 495us/step - loss: 0.0824 - val_loss: 0.0826\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 757us/step - loss: 0.0823 - val_loss: 0.0819\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 695us/step - loss: 0.0822 - val_loss: 0.0823\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 727us/step - loss: 0.0822 - val_loss: 0.0821\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 444us/step - loss: 0.0821 - val_loss: 0.0832\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 436us/step - loss: 0.0823 - val_loss: 0.0819\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 543us/step - loss: 0.0822 - val_loss: 0.0823\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 483us/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 602us/step - loss: 0.0821 - val_loss: 0.0819\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 620us/step - loss: 0.0821 - val_loss: 0.0817\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 458us/step - loss: 0.0820 - val_loss: 0.0823\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 471us/step - loss: 0.0821 - val_loss: 0.0817\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 575us/step - loss: 0.0820 - val_loss: 0.0820\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 563us/step - loss: 0.0821 - val_loss: 0.0816\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 619us/step - loss: 0.0819 - val_loss: 0.0816\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 461us/step - loss: 0.0818 - val_loss: 0.0827\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 577us/step - loss: 0.0819 - val_loss: 0.0821\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 490us/step - loss: 0.0818 - val_loss: 0.0819\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 549us/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 661us/step - loss: 0.0816 - val_loss: 0.0816\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 630us/step - loss: 0.0817 - val_loss: 0.0818\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 483us/step - loss: 0.0817 - val_loss: 0.0815\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 592us/step - loss: 0.0817 - val_loss: 0.0817\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 445us/step - loss: 0.0816 - val_loss: 0.0816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 435us/step - loss: 0.0817 - val_loss: 0.0816\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 720us/step - loss: 0.0815 - val_loss: 0.0813\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 606us/step - loss: 0.0816 - val_loss: 0.0821\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 533us/step - loss: 0.0816 - val_loss: 0.0815\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 487us/step - loss: 0.0815 - val_loss: 0.0826\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 599us/step - loss: 0.0813 - val_loss: 0.0817\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 577us/step - loss: 0.0814 - val_loss: 0.0817\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 444us/step - loss: 0.0815 - val_loss: 0.0810\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 594us/step - loss: 0.0813 - val_loss: 0.0811\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 574us/step - loss: 0.0814 - val_loss: 0.0812\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 429us/step - loss: 0.0812 - val_loss: 0.0812\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 591us/step - loss: 0.0813 - val_loss: 0.0817\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 638us/step - loss: 0.0813 - val_loss: 0.0819\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 431us/step - loss: 0.0812 - val_loss: 0.0810\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 590us/step - loss: 0.0812 - val_loss: 0.0817\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 588us/step - loss: 0.0811 - val_loss: 0.0814\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 459us/step - loss: 0.0812 - val_loss: 0.0812\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 442us/step - loss: 0.0810 - val_loss: 0.0810\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 470us/step - loss: 0.0812 - val_loss: 0.0814\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 500us/step - loss: 0.0811 - val_loss: 0.0811\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 437us/step - loss: 0.0809 - val_loss: 0.0809\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 502us/step - loss: 0.0810 - val_loss: 0.0811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f462588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss\n",
    "\n",
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2_my = Dense(1, activation='linear')(encoder_my.output)\n",
    "newmodel_my = Model(encoder_my.input,out2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newmodel_my.compile(loss='mean_squared_error', optimizer='rmsprop', \n",
    "          metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 233 samples\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 320us/step - loss: 16.3232 - acc: 0.0000e+00 - val_loss: 13.8560 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 13.2838 - acc: 0.0000e+00 - val_loss: 11.9793 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 56us/step - loss: 11.5975 - acc: 0.0000e+00 - val_loss: 10.7576 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 10.4415 - acc: 0.0000e+00 - val_loss: 9.8548 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 67us/step - loss: 9.5751 - acc: 0.0000e+00 - val_loss: 9.1450 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 8.8898 - acc: 0.0000e+00 - val_loss: 8.5749 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 71us/step - loss: 8.3380 - acc: 0.0000e+00 - val_loss: 8.1003 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 7.8796 - acc: 0.0000e+00 - val_loss: 7.7046 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 62us/step - loss: 7.4971 - acc: 0.0000e+00 - val_loss: 7.3671 - val_acc: 0.0043\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 7.1686 - acc: 0.0044 - val_loss: 7.0671 - val_acc: 0.0043\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 56us/step - loss: 6.8789 - acc: 0.0067 - val_loss: 6.8063 - val_acc: 0.0043\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 59us/step - loss: 6.6261 - acc: 0.0089 - val_loss: 6.5701 - val_acc: 0.0043\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 6.3985 - acc: 0.0111 - val_loss: 6.3607 - val_acc: 0.0043\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 70us/step - loss: 6.1972 - acc: 0.0133 - val_loss: 6.1721 - val_acc: 0.0043\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 63us/step - loss: 6.0167 - acc: 0.0133 - val_loss: 6.0009 - val_acc: 0.0043\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 5.8531 - acc: 0.0133 - val_loss: 5.8432 - val_acc: 0.0043\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 59us/step - loss: 5.7031 - acc: 0.0133 - val_loss: 5.6991 - val_acc: 0.0043\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 5.5667 - acc: 0.0133 - val_loss: 5.5699 - val_acc: 0.0086\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 5.4443 - acc: 0.0156 - val_loss: 5.4507 - val_acc: 0.0086\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 5.3314 - acc: 0.0156 - val_loss: 5.3401 - val_acc: 0.0086\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 5.2268 - acc: 0.0156 - val_loss: 5.2373 - val_acc: 0.0086\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 4.9346 - acc: 0.015 - 0s 67us/step - loss: 5.1294 - acc: 0.0178 - val_loss: 5.1425 - val_acc: 0.0086\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 62us/step - loss: 5.0391 - acc: 0.0200 - val_loss: 5.0527 - val_acc: 0.0086\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 70us/step - loss: 4.9538 - acc: 0.0200 - val_loss: 4.9693 - val_acc: 0.0086\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 63us/step - loss: 4.8740 - acc: 0.0200 - val_loss: 4.8906 - val_acc: 0.0086\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 59us/step - loss: 4.7987 - acc: 0.0200 - val_loss: 4.8164 - val_acc: 0.0086\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 68us/step - loss: 4.7275 - acc: 0.0200 - val_loss: 4.7465 - val_acc: 0.0086\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 4.6600 - acc: 0.0200 - val_loss: 4.6796 - val_acc: 0.0086\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 63us/step - loss: 4.5951 - acc: 0.0200 - val_loss: 4.6150 - val_acc: 0.0086\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 4.6156 - acc: 0.0000e+0 - 0s 81us/step - loss: 4.5328 - acc: 0.0200 - val_loss: 4.5536 - val_acc: 0.0086\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 57us/step - loss: 4.4728 - acc: 0.0200 - val_loss: 4.4940 - val_acc: 0.0086\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 4.4148 - acc: 0.0200 - val_loss: 4.4366 - val_acc: 0.0086\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 4.3585 - acc: 0.0200 - val_loss: 4.3802 - val_acc: 0.0086\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 57us/step - loss: 4.3035 - acc: 0.0200 - val_loss: 4.3262 - val_acc: 0.0086\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 4.2502 - acc: 0.0200 - val_loss: 4.2722 - val_acc: 0.0086\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 4.1973 - acc: 0.0200 - val_loss: 4.2207 - val_acc: 0.0086\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 63us/step - loss: 4.1461 - acc: 0.0200 - val_loss: 4.1683 - val_acc: 0.0086\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 4.0942 - acc: 0.0200 - val_loss: 4.1160 - val_acc: 0.0086\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 4.0421 - acc: 0.0200 - val_loss: 4.0629 - val_acc: 0.0086\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 44us/step - loss: 3.9887 - acc: 0.0200 - val_loss: 4.0067 - val_acc: 0.0086\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 57us/step - loss: 3.9307 - acc: 0.0200 - val_loss: 3.9422 - val_acc: 0.0086\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 3.8603 - acc: 0.0200 - val_loss: 3.8558 - val_acc: 0.0086\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 65us/step - loss: 3.7575 - acc: 0.0200 - val_loss: 3.7257 - val_acc: 0.0086\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 3.6225 - acc: 0.0200 - val_loss: 3.6090 - val_acc: 0.0086\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 3.5170 - acc: 0.0200 - val_loss: 3.5225 - val_acc: 0.0086\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 3.4362 - acc: 0.0200 - val_loss: 3.4490 - val_acc: 0.0086\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 3.3659 - acc: 0.0200 - val_loss: 3.3818 - val_acc: 0.0086\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 3.3009 - acc: 0.0200 - val_loss: 3.3187 - val_acc: 0.0086\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 67us/step - loss: 3.2394 - acc: 0.0200 - val_loss: 3.2582 - val_acc: 0.0086\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 3.0355 - acc: 0.007 - 0s 52us/step - loss: 3.1805 - acc: 0.0200 - val_loss: 3.2005 - val_acc: 0.0086\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 56us/step - loss: 3.1237 - acc: 0.0200 - val_loss: 3.1436 - val_acc: 0.0086\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 46us/step - loss: 3.0678 - acc: 0.0200 - val_loss: 3.0884 - val_acc: 0.0086\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 59us/step - loss: 3.0133 - acc: 0.0200 - val_loss: 3.0341 - val_acc: 0.0086\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 2.9597 - acc: 0.0200 - val_loss: 2.9809 - val_acc: 0.0086\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 2.9075 - acc: 0.0200 - val_loss: 2.9302 - val_acc: 0.0086\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 2.8572 - acc: 0.0200 - val_loss: 2.8800 - val_acc: 0.0086\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 2.8074 - acc: 0.0200 - val_loss: 2.8303 - val_acc: 0.0086\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 47us/step - loss: 2.7581 - acc: 0.0200 - val_loss: 2.7814 - val_acc: 0.0086\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 61us/step - loss: 2.7097 - acc: 0.0200 - val_loss: 2.7336 - val_acc: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 2.6622 - acc: 0.0200 - val_loss: 2.6858 - val_acc: 0.0086\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 2.6142 - acc: 0.0200 - val_loss: 2.6366 - val_acc: 0.0086\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 62us/step - loss: 2.5620 - acc: 0.0200 - val_loss: 2.5710 - val_acc: 0.0429\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 45us/step - loss: 2.4849 - acc: 0.1511 - val_loss: 2.4861 - val_acc: 0.2833\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 68us/step - loss: 2.4063 - acc: 0.2289 - val_loss: 2.4194 - val_acc: 0.2833\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 2.3423 - acc: 0.2289 - val_loss: 2.3584 - val_acc: 0.2833\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 2.2831 - acc: 0.2289 - val_loss: 2.3016 - val_acc: 0.2833\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 2.2274 - acc: 0.2289 - val_loss: 2.2473 - val_acc: 0.2833\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 48us/step - loss: 2.1741 - acc: 0.2289 - val_loss: 2.1951 - val_acc: 0.2833\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 2.1224 - acc: 0.2289 - val_loss: 2.1437 - val_acc: 0.2833\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 62us/step - loss: 2.0717 - acc: 0.2289 - val_loss: 2.0944 - val_acc: 0.2833\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 2.0229 - acc: 0.2289 - val_loss: 2.0456 - val_acc: 0.2833\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 45us/step - loss: 1.9747 - acc: 0.2289 - val_loss: 1.9985 - val_acc: 0.2833\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 57us/step - loss: 1.9278 - acc: 0.2289 - val_loss: 1.9514 - val_acc: 0.2833\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 1.8811 - acc: 0.2289 - val_loss: 1.9054 - val_acc: 0.2833\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 56us/step - loss: 1.8356 - acc: 0.2289 - val_loss: 1.8605 - val_acc: 0.2833\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 1.7911 - acc: 0.2289 - val_loss: 1.8169 - val_acc: 0.2833\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 51us/step - loss: 1.7477 - acc: 0.2289 - val_loss: 1.7740 - val_acc: 0.2833\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 52us/step - loss: 1.7052 - acc: 0.2289 - val_loss: 1.7319 - val_acc: 0.2833\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 1.6631 - acc: 0.2289 - val_loss: 1.6885 - val_acc: 0.2833\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 59us/step - loss: 1.6143 - acc: 0.2289 - val_loss: 1.6039 - val_acc: 0.2833\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 56us/step - loss: 1.5075 - acc: 0.2289 - val_loss: 1.5078 - val_acc: 0.2833\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 38us/step - loss: 1.4305 - acc: 0.2289 - val_loss: 1.4498 - val_acc: 0.2833\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 53us/step - loss: 1.3773 - acc: 0.2289 - val_loss: 1.4020 - val_acc: 0.2833\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 49us/step - loss: 1.3314 - acc: 0.2289 - val_loss: 1.3573 - val_acc: 0.2833\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 43us/step - loss: 1.2879 - acc: 0.2289 - val_loss: 1.3143 - val_acc: 0.2833\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 1.2457 - acc: 0.2289 - val_loss: 1.2727 - val_acc: 0.2833\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 45us/step - loss: 1.2038 - acc: 0.2289 - val_loss: 1.2238 - val_acc: 0.2833\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 1.1419 - acc: 0.2289 - val_loss: 1.1506 - val_acc: 0.2833\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 1.0757 - acc: 0.2289 - val_loss: 1.0976 - val_acc: 0.2833\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 74us/step - loss: 1.0264 - acc: 0.2289 - val_loss: 1.0535 - val_acc: 0.2833\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 83us/step - loss: 0.9843 - acc: 0.2289 - val_loss: 1.0140 - val_acc: 0.2833\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.9463 - acc: 0.2289 - val_loss: 0.9777 - val_acc: 0.2833\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.9113 - acc: 0.2289 - val_loss: 0.9442 - val_acc: 0.2833\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 68us/step - loss: 0.8786 - acc: 0.2289 - val_loss: 0.9120 - val_acc: 0.2833\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 66us/step - loss: 0.8475 - acc: 0.2289 - val_loss: 0.8822 - val_acc: 0.2833\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.8183 - acc: 0.2289 - val_loss: 0.8539 - val_acc: 0.2833\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 54us/step - loss: 0.7909 - acc: 0.2289 - val_loss: 0.8274 - val_acc: 0.2833\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 50us/step - loss: 0.7650 - acc: 0.2289 - val_loss: 0.8024 - val_acc: 0.2833\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 55us/step - loss: 0.7407 - acc: 0.2289 - val_loss: 0.7797 - val_acc: 0.2833\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.7183 - acc: 0.2289 - val_loss: 0.7573 - val_acc: 0.2833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f7dd2b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel_my.fit(X_train_my, Y_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, Y_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 [==============================] - 0s 192us/step\n",
      "0.757279897251\n",
      "233/233 [==============================] - 0s 54us/step\n",
      "[ 2.47989511  2.4798727   2.47990155  2.47985506  2.47319388  2.47990251\n",
      "  2.47990227  2.47990251  2.47317767  2.47989798  2.47990251  2.47866964\n",
      "  2.47476625  2.479738    2.47932315  2.47990251  2.47680306  2.47979641\n",
      "  2.47648859  2.47317767  2.47982812  2.47777224  2.4696629   2.46404672\n",
      "  2.47982717  2.47990251  2.47985053  2.4696629   2.47990251  2.4696629\n",
      "  2.47959733  2.47989821  2.47990155  2.46404672  2.47990227  2.47923923\n",
      "  2.47990251  2.47989178  2.47990251  2.47746706  2.47965527  2.47990251\n",
      "  2.47990227  2.47990084  2.47985244  2.46404672  2.47476625  2.47468638\n",
      "  2.47956395  2.47990251  2.47990251  2.47271013  2.47317767  2.46864033\n",
      "  2.47990251  2.47814775  2.47924781  2.47543192  2.47980928  2.47983837\n",
      "  2.47984791  2.47628999  2.47391558  2.47990251  2.47989774  2.47476625\n",
      "  2.4696629   2.47945285  2.47990251  2.47980952  2.47990251  2.47986841\n",
      "  2.47990251  2.47838712  2.47990084  2.47988939  2.47980809  2.47989988\n",
      "  2.47990251  2.47989821  2.47827029  2.47988415  2.47924781  2.47981024\n",
      "  2.47969079  2.47724271  2.4793129   2.47988915  2.47990227  2.4696629\n",
      "  2.47990227  2.47988892  2.47990227  2.47799516  2.47987485  2.47935271\n",
      "  2.47990108  2.47986507  2.47990108  2.47989917  2.47986221  2.46404672\n",
      "  2.47939873  2.47990227  2.47990251  2.47375822  2.47990227  2.4797287\n",
      "  2.47990227  2.46404672  2.47643757  2.47912335  2.47988415  2.47559094\n",
      "  2.47985768  2.47990251  2.47990131  2.47961116  2.47738624  2.47990251\n",
      "  2.4696629   2.47640371  2.47990084  2.47990179  2.47317767  2.47970438\n",
      "  2.47990108  2.47978878  2.4798975   2.47987723  2.47972465  2.47985554\n",
      "  2.47815967  2.47990179  2.47978401  2.46404672  2.4774251   2.47989178\n",
      "  2.4696629   2.47978878  2.46404672  2.47990251  2.47986889  2.47956347\n",
      "  2.4798553   2.47620177  2.47463393  2.47990251  2.47985029  2.47604346\n",
      "  2.4696629   2.47413778  2.47990251  2.47944856  2.47975779  2.47955585\n",
      "  2.4792788   2.47209668  2.47929001  2.47979879  2.47990251  2.47309995\n",
      "  2.47979593  2.47984624  2.47988105  2.47989821  2.4696629   2.47317767\n",
      "  2.47542429  2.4696629   2.46636176  2.4696629   2.47990251  2.47990251\n",
      "  2.47987962  2.47317767  2.4782896   2.46404672  2.47988391  2.47977686\n",
      "  2.47800756  2.47990131  2.47990251  2.47990251  2.4696629   2.47990108\n",
      "  2.47990155  2.47989464  2.47938251  2.47964311  2.47884154  2.47985959\n",
      "  2.47988391  2.47990251  2.47990251  2.47990251  2.4696629   2.47847962\n",
      "  2.47958517  2.47848201  2.4757576   2.47381663  2.47946763  2.47990251\n",
      "  2.47259498  2.47944593  2.47304797  2.47989845  2.47930217  2.47990227\n",
      "  2.47990131  2.47317767  2.47981548  2.4798553   2.479671    2.47989821\n",
      "  2.47952485  2.47990155  2.47990084  2.47990251  2.4696629   2.47843051\n",
      "  2.47317767  2.47989607  2.47955132  2.47990131  2.47987413  2.47989011\n",
      "  2.4796257   2.47990203  2.47972035  2.47990084  2.47990251]\n",
      "233/233 [==============================] - 0s 69us/step\n",
      "[ 2.  3.  2.  2.  2.  3.  3.  3.  4.  3.  3.  3.  3.  3.  3.  3.  3.  2.\n",
      "  4.  4.  2.  3.  3.  2.  2.  3.  3.  3.  4.  3.  3.  2.  2.  2.  3.  5.\n",
      "  2.  3.  3.  3.  3.  2.  2.  3.  2.  2.  3.  3.  3.  3.  4.  3.  4.  2.\n",
      "  4.  2.  2.  5.  3.  3.  3.  2.  3.  4.  3.  3.  3.  4.  3.  3.  3.  3.\n",
      "  5.  3.  3.  2.  4.  3.  3.  3.  3.  3.  3.  2.  2.  4.  5.  3.  3.  3.\n",
      "  3.  3.  5.  3.  3.  4.  3.  3.  3.  2.  3.  2.  2.  3.  4.  3.  3.  2.\n",
      "  2.  2.  3.  2.  2.  2.  2.  3.  3.  2.  2.  2.  3.  2.  3.  4.  4.  3.\n",
      "  3.  3.  3.  2.  3.  2.  2.  4.  2.  2.  4.  3.  3.  2.  2.  2.  2.  2.\n",
      "  3.  3.  2.  4.  4.  2.  3.  2.  3.  3.  3.  3.  3.  2.  3.  3.  3.  3.\n",
      "  2.  4.  3.  4.  3.  4.  3.  3.  2.  3.  5.  3.  3.  4.  2.  2.  3.  3.\n",
      "  3.  2.  3.  4.  3.  4.  3.  4.  2.  2.  4.  3.  3.  2.  4.  3.  3.  4.\n",
      "  3.  3.  2.  3.  2.  4.  1.  4.  3.  2.  3.  3.  3.  4.  2.  3.  3.  2.\n",
      "  3.  2.  3.  4.  3.  3.  4.  4.  1.  3.  3.  3.  3.  4.  3.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "#print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(newmodel_my.predict(X_test_my, verbose=1).flatten(), Y_test_my)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "#print('Rounded')\n",
    "#print(np.around(newmodel_my.predict(X_test_my, verbose=1).flatten(),decimals=0))\n",
    "\n",
    "scores_my = newmodel_my.evaluate(X_test_my, Y_test_my, verbose=1) \n",
    "print(y_test_my)\n",
    "\n",
    "#print(\"Accuracy: \", scores_my[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
