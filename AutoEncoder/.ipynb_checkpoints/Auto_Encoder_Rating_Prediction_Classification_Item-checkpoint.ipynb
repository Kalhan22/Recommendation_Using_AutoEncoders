{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "from tensorflow.python.ops.variables import trainable_variables\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train_my = genfromtxt('../UserData/655/trainX_item_655.csv', delimiter=',')\n",
    "y_train_my = genfromtxt('../UserData/655/trainY_item_655.csv', delimiter=',')\n",
    "X_test_my = genfromtxt('../UserData/655/testX_item_655.csv', delimiter=',')\n",
    "y_test_my = genfromtxt('../UserData/655/testY_item_655.csv', delimiter=',')\n",
    "\n",
    "num_classes_my = 6 # there are 5 classes (1 per rating class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train_my = X_train_my.astype('float32') \n",
    "X_train_my = X_train_my.astype('float32')\n",
    "print(X_train_my.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_my = np_utils.to_categorical(y_train_my, num_classes_my) # One-hot encode the labels\n",
    "\n",
    "Y_test_my = np_utils.to_categorical(y_test_my, num_classes_my) # One-hot encode the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_3:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_img_my = Input(shape=(20,))\n",
    "\n",
    "print(input_img_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_9/Relu:0\", shape=(?, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_my = Dense(20, activation='relu')(input_img_my)\n",
    "print(x_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded1_my = Dense(15, activation='relu')(x_my)\n",
    "encoded2_my = Dense(12, activation='relu')(encoded1_my)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_my = Dense(10, activation='relu')(encoded2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded2_my = Dense(12, activation='relu')(y_my)\n",
    "decoded1_my = Dense(15, activation='relu')(decoded2_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_my = Dense(20, activation='sigmoid')(decoded1_my)\n",
    "autoencoder_my = Model(input_img_my, z_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x1129fa320>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "print(encoder_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_my.compile(optimizer='adadelta', loss='mse') # reporting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 20)\n",
      "(402, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_my.shape)\n",
    "\n",
    "print(X_train_my.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 171 samples\n",
      "Epoch 1/50\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.9850 - val_loss: 1.0039\n",
      "Epoch 2/50\n",
      "402/402 [==============================] - 0s 629us/step - loss: 0.9323 - val_loss: 0.8285\n",
      "Epoch 3/50\n",
      "402/402 [==============================] - 0s 654us/step - loss: 0.6394 - val_loss: 0.6154\n",
      "Epoch 4/50\n",
      "402/402 [==============================] - 0s 631us/step - loss: 0.5915 - val_loss: 0.6136\n",
      "Epoch 5/50\n",
      "402/402 [==============================] - 0s 787us/step - loss: 0.5904 - val_loss: 0.6132\n",
      "Epoch 6/50\n",
      "402/402 [==============================] - 0s 643us/step - loss: 0.5901 - val_loss: 0.6125\n",
      "Epoch 7/50\n",
      "402/402 [==============================] - 0s 609us/step - loss: 0.5897 - val_loss: 0.6121\n",
      "Epoch 8/50\n",
      "402/402 [==============================] - 0s 693us/step - loss: 0.5890 - val_loss: 0.6114\n",
      "Epoch 9/50\n",
      "402/402 [==============================] - 0s 850us/step - loss: 0.5874 - val_loss: 0.6093\n",
      "Epoch 10/50\n",
      "402/402 [==============================] - 0s 618us/step - loss: 0.5866 - val_loss: 0.6097\n",
      "Epoch 11/50\n",
      "402/402 [==============================] - 0s 640us/step - loss: 0.5861 - val_loss: 0.6091\n",
      "Epoch 12/50\n",
      "402/402 [==============================] - 0s 679us/step - loss: 0.5857 - val_loss: 0.6079\n",
      "Epoch 13/50\n",
      "402/402 [==============================] - 0s 634us/step - loss: 0.5850 - val_loss: 0.6085\n",
      "Epoch 14/50\n",
      "402/402 [==============================] - 0s 631us/step - loss: 0.5845 - val_loss: 0.6067\n",
      "Epoch 15/50\n",
      "402/402 [==============================] - 0s 650us/step - loss: 0.5837 - val_loss: 0.6061\n",
      "Epoch 16/50\n",
      "402/402 [==============================] - 0s 905us/step - loss: 0.5828 - val_loss: 0.6051\n",
      "Epoch 17/50\n",
      "402/402 [==============================] - 0s 776us/step - loss: 0.5817 - val_loss: 0.6040\n",
      "Epoch 18/50\n",
      "402/402 [==============================] - 0s 717us/step - loss: 0.5803 - val_loss: 0.6027\n",
      "Epoch 19/50\n",
      "402/402 [==============================] - 0s 629us/step - loss: 0.5788 - val_loss: 0.6011\n",
      "Epoch 20/50\n",
      "402/402 [==============================] - 0s 833us/step - loss: 0.5771 - val_loss: 0.5995\n",
      "Epoch 21/50\n",
      "402/402 [==============================] - 0s 701us/step - loss: 0.5754 - val_loss: 0.5981\n",
      "Epoch 22/50\n",
      "402/402 [==============================] - 0s 626us/step - loss: 0.5739 - val_loss: 0.5974\n",
      "Epoch 23/50\n",
      "402/402 [==============================] - 0s 784us/step - loss: 0.5727 - val_loss: 0.5960\n",
      "Epoch 24/50\n",
      "402/402 [==============================] - 0s 859us/step - loss: 0.5717 - val_loss: 0.5950\n",
      "Epoch 25/50\n",
      "402/402 [==============================] - 0s 643us/step - loss: 0.5707 - val_loss: 0.5943\n",
      "Epoch 26/50\n",
      "402/402 [==============================] - 0s 798us/step - loss: 0.5700 - val_loss: 0.5934\n",
      "Epoch 27/50\n",
      "402/402 [==============================] - 0s 711us/step - loss: 0.5693 - val_loss: 0.5929\n",
      "Epoch 28/50\n",
      "402/402 [==============================] - 0s 651us/step - loss: 0.5685 - val_loss: 0.5920\n",
      "Epoch 29/50\n",
      "402/402 [==============================] - 0s 805us/step - loss: 0.5680 - val_loss: 0.5923\n",
      "Epoch 30/50\n",
      "402/402 [==============================] - 0s 660us/step - loss: 0.5675 - val_loss: 0.5910\n",
      "Epoch 31/50\n",
      "402/402 [==============================] - 0s 667us/step - loss: 0.5670 - val_loss: 0.5905\n",
      "Epoch 32/50\n",
      "402/402 [==============================] - 0s 747us/step - loss: 0.5666 - val_loss: 0.5901\n",
      "Epoch 33/50\n",
      "402/402 [==============================] - 0s 758us/step - loss: 0.5663 - val_loss: 0.5898\n",
      "Epoch 34/50\n",
      "402/402 [==============================] - 0s 920us/step - loss: 0.5659 - val_loss: 0.5895\n",
      "Epoch 35/50\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5892\n",
      "Epoch 36/50\n",
      "402/402 [==============================] - 0s 763us/step - loss: 0.5653 - val_loss: 0.5888\n",
      "Epoch 37/50\n",
      "402/402 [==============================] - 0s 686us/step - loss: 0.5650 - val_loss: 0.5886\n",
      "Epoch 38/50\n",
      "402/402 [==============================] - 0s 756us/step - loss: 0.5648 - val_loss: 0.5883\n",
      "Epoch 39/50\n",
      "402/402 [==============================] - 0s 781us/step - loss: 0.5646 - val_loss: 0.5881\n",
      "Epoch 40/50\n",
      "402/402 [==============================] - 0s 688us/step - loss: 0.5643 - val_loss: 0.5879\n",
      "Epoch 41/50\n",
      "402/402 [==============================] - 0s 790us/step - loss: 0.5641 - val_loss: 0.5877\n",
      "Epoch 42/50\n",
      "402/402 [==============================] - 0s 705us/step - loss: 0.5639 - val_loss: 0.5874\n",
      "Epoch 43/50\n",
      "402/402 [==============================] - 0s 646us/step - loss: 0.5636 - val_loss: 0.5873\n",
      "Epoch 44/50\n",
      "402/402 [==============================] - 0s 832us/step - loss: 0.5634 - val_loss: 0.5869\n",
      "Epoch 45/50\n",
      "402/402 [==============================] - 0s 660us/step - loss: 0.5630 - val_loss: 0.5866\n",
      "Epoch 46/50\n",
      "402/402 [==============================] - 0s 631us/step - loss: 0.5626 - val_loss: 0.5861\n",
      "Epoch 47/50\n",
      "402/402 [==============================] - 0s 847us/step - loss: 0.5621 - val_loss: 0.5858\n",
      "Epoch 48/50\n",
      "402/402 [==============================] - 0s 708us/step - loss: 0.5617 - val_loss: 0.5854\n",
      "Epoch 49/50\n",
      "402/402 [==============================] - 0s 637us/step - loss: 0.5614 - val_loss: 0.5852\n",
      "Epoch 50/50\n",
      "402/402 [==============================] - 0s 799us/step - loss: 0.5611 - val_loss: 0.5847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112b11828>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 171 samples\n",
      "Epoch 1/50\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.5607 - val_loss: 0.5845\n",
      "Epoch 2/50\n",
      "402/402 [==============================] - 0s 628us/step - loss: 0.5603 - val_loss: 0.5839\n",
      "Epoch 3/50\n",
      "402/402 [==============================] - 0s 624us/step - loss: 0.5599 - val_loss: 0.5839\n",
      "Epoch 4/50\n",
      "402/402 [==============================] - 0s 660us/step - loss: 0.5595 - val_loss: 0.5835\n",
      "Epoch 5/50\n",
      "402/402 [==============================] - 0s 632us/step - loss: 0.5591 - val_loss: 0.5829\n",
      "Epoch 6/50\n",
      "402/402 [==============================] - 0s 762us/step - loss: 0.5587 - val_loss: 0.5827\n",
      "Epoch 7/50\n",
      "402/402 [==============================] - 0s 747us/step - loss: 0.5583 - val_loss: 0.5822\n",
      "Epoch 8/50\n",
      "402/402 [==============================] - 0s 645us/step - loss: 0.5580 - val_loss: 0.5826\n",
      "Epoch 9/50\n",
      "402/402 [==============================] - 0s 670us/step - loss: 0.5576 - val_loss: 0.5817\n",
      "Epoch 10/50\n",
      "402/402 [==============================] - 0s 652us/step - loss: 0.5572 - val_loss: 0.5813\n",
      "Epoch 11/50\n",
      "402/402 [==============================] - 0s 622us/step - loss: 0.5569 - val_loss: 0.5813\n",
      "Epoch 12/50\n",
      "402/402 [==============================] - 0s 644us/step - loss: 0.5566 - val_loss: 0.5812\n",
      "Epoch 13/50\n",
      "402/402 [==============================] - 0s 613us/step - loss: 0.5563 - val_loss: 0.5806\n",
      "Epoch 14/50\n",
      "402/402 [==============================] - 0s 659us/step - loss: 0.5560 - val_loss: 0.5806\n",
      "Epoch 15/50\n",
      "402/402 [==============================] - 0s 630us/step - loss: 0.5557 - val_loss: 0.5801\n",
      "Epoch 16/50\n",
      "402/402 [==============================] - 0s 859us/step - loss: 0.5554 - val_loss: 0.5798\n",
      "Epoch 17/50\n",
      "402/402 [==============================] - 0s 637us/step - loss: 0.5551 - val_loss: 0.5798\n",
      "Epoch 18/50\n",
      "402/402 [==============================] - 0s 620us/step - loss: 0.5549 - val_loss: 0.5793\n",
      "Epoch 19/50\n",
      "402/402 [==============================] - 0s 826us/step - loss: 0.5546 - val_loss: 0.5797\n",
      "Epoch 20/50\n",
      "402/402 [==============================] - 0s 630us/step - loss: 0.5544 - val_loss: 0.5790\n",
      "Epoch 21/50\n",
      "402/402 [==============================] - 0s 785us/step - loss: 0.5541 - val_loss: 0.5787\n",
      "Epoch 22/50\n",
      "402/402 [==============================] - 0s 752us/step - loss: 0.5539 - val_loss: 0.5784\n",
      "Epoch 23/50\n",
      "402/402 [==============================] - 0s 636us/step - loss: 0.5535 - val_loss: 0.5785\n",
      "Epoch 24/50\n",
      "402/402 [==============================] - 0s 875us/step - loss: 0.5534 - val_loss: 0.5781\n",
      "Epoch 25/50\n",
      "402/402 [==============================] - 0s 735us/step - loss: 0.5531 - val_loss: 0.5783\n",
      "Epoch 26/50\n",
      "402/402 [==============================] - 0s 416us/step - loss: 0.5529 - val_loss: 0.5778\n",
      "Epoch 27/50\n",
      "402/402 [==============================] - 0s 661us/step - loss: 0.5527 - val_loss: 0.5774\n",
      "Epoch 28/50\n",
      "402/402 [==============================] - 0s 619us/step - loss: 0.5524 - val_loss: 0.5773\n",
      "Epoch 29/50\n",
      "402/402 [==============================] - 0s 742us/step - loss: 0.5522 - val_loss: 0.5771\n",
      "Epoch 30/50\n",
      "402/402 [==============================] - 0s 712us/step - loss: 0.5520 - val_loss: 0.5768\n",
      "Epoch 31/50\n",
      "402/402 [==============================] - 0s 703us/step - loss: 0.5518 - val_loss: 0.5768\n",
      "Epoch 32/50\n",
      "402/402 [==============================] - 0s 779us/step - loss: 0.5516 - val_loss: 0.5763\n",
      "Epoch 33/50\n",
      "402/402 [==============================] - 0s 648us/step - loss: 0.5514 - val_loss: 0.5773\n",
      "Epoch 34/50\n",
      "402/402 [==============================] - 0s 790us/step - loss: 0.5513 - val_loss: 0.5760\n",
      "Epoch 35/50\n",
      "402/402 [==============================] - 0s 670us/step - loss: 0.5510 - val_loss: 0.5760\n",
      "Epoch 36/50\n",
      "402/402 [==============================] - 0s 716us/step - loss: 0.5508 - val_loss: 0.5757\n",
      "Epoch 37/50\n",
      "402/402 [==============================] - 0s 781us/step - loss: 0.5506 - val_loss: 0.5757\n",
      "Epoch 38/50\n",
      "402/402 [==============================] - 0s 784us/step - loss: 0.5504 - val_loss: 0.5754\n",
      "Epoch 39/50\n",
      "402/402 [==============================] - 0s 695us/step - loss: 0.5503 - val_loss: 0.5753\n",
      "Epoch 40/50\n",
      "402/402 [==============================] - 0s 706us/step - loss: 0.5501 - val_loss: 0.5753\n",
      "Epoch 41/50\n",
      "402/402 [==============================] - 0s 743us/step - loss: 0.5500 - val_loss: 0.5750\n",
      "Epoch 42/50\n",
      "402/402 [==============================] - 0s 704us/step - loss: 0.5499 - val_loss: 0.5750\n",
      "Epoch 43/50\n",
      "402/402 [==============================] - 0s 918us/step - loss: 0.5496 - val_loss: 0.5748\n",
      "Epoch 44/50\n",
      "402/402 [==============================] - 0s 801us/step - loss: 0.5495 - val_loss: 0.5748\n",
      "Epoch 45/50\n",
      "402/402 [==============================] - 0s 641us/step - loss: 0.5494 - val_loss: 0.5745\n",
      "Epoch 46/50\n",
      "402/402 [==============================] - 0s 835us/step - loss: 0.5492 - val_loss: 0.5744\n",
      "Epoch 47/50\n",
      "402/402 [==============================] - 0s 661us/step - loss: 0.5491 - val_loss: 0.5743\n",
      "Epoch 48/50\n",
      "402/402 [==============================] - 0s 609us/step - loss: 0.5490 - val_loss: 0.5744\n",
      "Epoch 49/50\n",
      "402/402 [==============================] - 0s 776us/step - loss: 0.5488 - val_loss: 0.5747\n",
      "Epoch 50/50\n",
      "402/402 [==============================] - 0s 731us/step - loss: 0.5487 - val_loss: 0.5741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112b11710>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "autoencoder_my.compile(optimizer='adadelta', loss='mse') # reporting the loss\n",
    "\n",
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2_my = Dense(6, activation='softmax')(encoder_my.output)\n",
    "newmodel_my = Model(encoder_my.input,out2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newmodel_my.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam', \n",
    "          metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 402 samples, validate on 171 samples\n",
      "Epoch 1/50\n",
      "402/402 [==============================] - 0s 607us/step - loss: 3.3905 - acc: 0.5025 - val_loss: 3.0043 - val_acc: 0.5731\n",
      "Epoch 2/50\n",
      "402/402 [==============================] - 0s 74us/step - loss: 2.8360 - acc: 0.5100 - val_loss: 2.4943 - val_acc: 0.5731\n",
      "Epoch 3/50\n",
      "402/402 [==============================] - 0s 66us/step - loss: 2.3268 - acc: 0.5323 - val_loss: 2.0610 - val_acc: 0.5497\n",
      "Epoch 4/50\n",
      "402/402 [==============================] - 0s 82us/step - loss: 1.9034 - acc: 0.5124 - val_loss: 1.7594 - val_acc: 0.4503\n",
      "Epoch 5/50\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.6176 - acc: 0.4975 - val_loss: 1.6279 - val_acc: 0.4211\n",
      "Epoch 6/50\n",
      "402/402 [==============================] - 0s 98us/step - loss: 1.4992 - acc: 0.4801 - val_loss: 1.6145 - val_acc: 0.3743\n",
      "Epoch 7/50\n",
      "402/402 [==============================] - 0s 75us/step - loss: 1.4753 - acc: 0.4776 - val_loss: 1.6187 - val_acc: 0.3684\n",
      "Epoch 8/50\n",
      "402/402 [==============================] - 0s 67us/step - loss: 1.4626 - acc: 0.4726 - val_loss: 1.5709 - val_acc: 0.3801\n",
      "Epoch 9/50\n",
      "402/402 [==============================] - 0s 74us/step - loss: 1.4155 - acc: 0.4801 - val_loss: 1.4913 - val_acc: 0.3801\n",
      "Epoch 10/50\n",
      "402/402 [==============================] - 0s 80us/step - loss: 1.3607 - acc: 0.4900 - val_loss: 1.4248 - val_acc: 0.4035\n",
      "Epoch 11/50\n",
      "402/402 [==============================] - 0s 71us/step - loss: 1.3172 - acc: 0.4975 - val_loss: 1.3776 - val_acc: 0.4386\n",
      "Epoch 12/50\n",
      "402/402 [==============================] - ETA: 0s - loss: 1.4178 - acc: 0.460 - 0s 73us/step - loss: 1.2856 - acc: 0.5050 - val_loss: 1.3440 - val_acc: 0.4503\n",
      "Epoch 13/50\n",
      "402/402 [==============================] - 0s 76us/step - loss: 1.2630 - acc: 0.5174 - val_loss: 1.3181 - val_acc: 0.4795\n",
      "Epoch 14/50\n",
      "402/402 [==============================] - 0s 70us/step - loss: 1.2427 - acc: 0.5224 - val_loss: 1.2987 - val_acc: 0.4678\n",
      "Epoch 15/50\n",
      "402/402 [==============================] - 0s 85us/step - loss: 1.2218 - acc: 0.5199 - val_loss: 1.2849 - val_acc: 0.4620\n",
      "Epoch 16/50\n",
      "402/402 [==============================] - 0s 82us/step - loss: 1.2020 - acc: 0.5124 - val_loss: 1.2748 - val_acc: 0.4678\n",
      "Epoch 17/50\n",
      "402/402 [==============================] - 0s 79us/step - loss: 1.1859 - acc: 0.5124 - val_loss: 1.2619 - val_acc: 0.4620\n",
      "Epoch 18/50\n",
      "402/402 [==============================] - 0s 83us/step - loss: 1.1734 - acc: 0.5149 - val_loss: 1.2471 - val_acc: 0.4678\n",
      "Epoch 19/50\n",
      "402/402 [==============================] - 0s 73us/step - loss: 1.1607 - acc: 0.5174 - val_loss: 1.2304 - val_acc: 0.4737\n",
      "Epoch 20/50\n",
      "402/402 [==============================] - 0s 69us/step - loss: 1.1509 - acc: 0.5348 - val_loss: 1.2152 - val_acc: 0.4912\n",
      "Epoch 21/50\n",
      "402/402 [==============================] - 0s 84us/step - loss: 1.1417 - acc: 0.5373 - val_loss: 1.2024 - val_acc: 0.5146\n",
      "Epoch 22/50\n",
      "402/402 [==============================] - 0s 73us/step - loss: 1.1331 - acc: 0.5597 - val_loss: 1.1932 - val_acc: 0.5731\n",
      "Epoch 23/50\n",
      "402/402 [==============================] - 0s 99us/step - loss: 1.1262 - acc: 0.5821 - val_loss: 1.1868 - val_acc: 0.5614\n",
      "Epoch 24/50\n",
      "402/402 [==============================] - 0s 92us/step - loss: 1.1181 - acc: 0.5896 - val_loss: 1.1814 - val_acc: 0.5614\n",
      "Epoch 25/50\n",
      "402/402 [==============================] - 0s 71us/step - loss: 1.1106 - acc: 0.5945 - val_loss: 1.1777 - val_acc: 0.5556\n",
      "Epoch 26/50\n",
      "402/402 [==============================] - 0s 72us/step - loss: 1.1045 - acc: 0.5721 - val_loss: 1.1800 - val_acc: 0.5322\n",
      "Epoch 27/50\n",
      "402/402 [==============================] - 0s 81us/step - loss: 1.0988 - acc: 0.5821 - val_loss: 1.1798 - val_acc: 0.5322\n",
      "Epoch 28/50\n",
      "402/402 [==============================] - 0s 71us/step - loss: 1.0936 - acc: 0.5920 - val_loss: 1.1755 - val_acc: 0.5322\n",
      "Epoch 29/50\n",
      "402/402 [==============================] - 0s 72us/step - loss: 1.0866 - acc: 0.6045 - val_loss: 1.1662 - val_acc: 0.5731\n",
      "Epoch 30/50\n",
      "402/402 [==============================] - 0s 80us/step - loss: 1.0795 - acc: 0.6244 - val_loss: 1.1559 - val_acc: 0.5731\n",
      "Epoch 31/50\n",
      "402/402 [==============================] - 0s 81us/step - loss: 1.0748 - acc: 0.6169 - val_loss: 1.1497 - val_acc: 0.5906\n",
      "Epoch 32/50\n",
      "402/402 [==============================] - 0s 76us/step - loss: 1.0701 - acc: 0.6169 - val_loss: 1.1450 - val_acc: 0.5789\n",
      "Epoch 33/50\n",
      "402/402 [==============================] - 0s 81us/step - loss: 1.0630 - acc: 0.6169 - val_loss: 1.1414 - val_acc: 0.5789\n",
      "Epoch 34/50\n",
      "402/402 [==============================] - 0s 79us/step - loss: 1.0558 - acc: 0.6294 - val_loss: 1.1404 - val_acc: 0.5731\n",
      "Epoch 35/50\n",
      "402/402 [==============================] - 0s 70us/step - loss: 1.0495 - acc: 0.6318 - val_loss: 1.1362 - val_acc: 0.5789\n",
      "Epoch 36/50\n",
      "402/402 [==============================] - 0s 98us/step - loss: 1.0437 - acc: 0.6318 - val_loss: 1.1317 - val_acc: 0.5789\n",
      "Epoch 37/50\n",
      "402/402 [==============================] - 0s 88us/step - loss: 1.0376 - acc: 0.6318 - val_loss: 1.1278 - val_acc: 0.5906\n",
      "Epoch 38/50\n",
      "402/402 [==============================] - 0s 105us/step - loss: 1.0313 - acc: 0.6418 - val_loss: 1.1251 - val_acc: 0.5731\n",
      "Epoch 39/50\n",
      "402/402 [==============================] - 0s 98us/step - loss: 1.0263 - acc: 0.6418 - val_loss: 1.1173 - val_acc: 0.5731\n",
      "Epoch 40/50\n",
      "402/402 [==============================] - 0s 86us/step - loss: 1.0195 - acc: 0.6493 - val_loss: 1.1053 - val_acc: 0.5906\n",
      "Epoch 41/50\n",
      "402/402 [==============================] - 0s 103us/step - loss: 1.0132 - acc: 0.6493 - val_loss: 1.1003 - val_acc: 0.5965\n",
      "Epoch 42/50\n",
      "402/402 [==============================] - 0s 133us/step - loss: 1.0066 - acc: 0.6542 - val_loss: 1.0950 - val_acc: 0.6023\n",
      "Epoch 43/50\n",
      "402/402 [==============================] - ETA: 0s - loss: 1.0700 - acc: 0.585 - 0s 87us/step - loss: 0.9993 - acc: 0.6567 - val_loss: 1.0868 - val_acc: 0.5965\n",
      "Epoch 44/50\n",
      "402/402 [==============================] - 0s 102us/step - loss: 0.9944 - acc: 0.6567 - val_loss: 1.0808 - val_acc: 0.6082\n",
      "Epoch 45/50\n",
      "402/402 [==============================] - 0s 99us/step - loss: 0.9869 - acc: 0.6592 - val_loss: 1.0783 - val_acc: 0.6140\n",
      "Epoch 46/50\n",
      "402/402 [==============================] - 0s 96us/step - loss: 0.9785 - acc: 0.6716 - val_loss: 1.0754 - val_acc: 0.6257\n",
      "Epoch 47/50\n",
      "402/402 [==============================] - 0s 71us/step - loss: 0.9723 - acc: 0.6891 - val_loss: 1.0760 - val_acc: 0.6316\n",
      "Epoch 48/50\n",
      "402/402 [==============================] - 0s 84us/step - loss: 0.9669 - acc: 0.6940 - val_loss: 1.0699 - val_acc: 0.6374\n",
      "Epoch 49/50\n",
      "402/402 [==============================] - ETA: 0s - loss: 0.9321 - acc: 0.664 - 0s 87us/step - loss: 0.9590 - acc: 0.6965 - val_loss: 1.0586 - val_acc: 0.6374\n",
      "Epoch 50/50\n",
      "402/402 [==============================] - 0s 101us/step - loss: 0.9496 - acc: 0.6990 - val_loss: 1.0508 - val_acc: 0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1137c3748>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel_my.fit(X_train_my, Y_train_my,\n",
    "      epochs=50,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, Y_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 539us/step\n",
      "[[  1.46562707e-05   3.46899033e-03   1.13145553e-01   6.32872343e-01\n",
      "    2.35245571e-01   1.52529022e-02]\n",
      " [  3.81464524e-05   3.15441424e-03   2.91548312e-01   5.13442993e-01\n",
      "    1.70811027e-01   2.10050959e-02]\n",
      " [  1.32536861e-05   4.43199463e-03   3.08617830e-01   3.91390085e-01\n",
      "    2.55533546e-01   4.00133580e-02]\n",
      " ..., \n",
      " [  2.96519283e-04   7.59420276e-04   5.34999371e-01   3.75863433e-01\n",
      "    7.22270682e-02   1.58541780e-02]\n",
      " [  2.38944249e-05   8.95209087e-04   2.42448628e-01   5.80342591e-01\n",
      "    1.60137400e-01   1.61522664e-02]\n",
      " [  7.38642193e-05   1.20616134e-03   1.28514960e-01   6.92377090e-01\n",
      "    1.66030779e-01   1.17972279e-02]]\n",
      "171/171 [==============================] - 0s 103us/step\n",
      "[3 3 3 2 3 3 3 3 3 2 3 3 3 3 3 3 2 2 3 3 2 3 3 3 3 2 3 2 3 2 3 3 3 2 3 2 2\n",
      " 3 2 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 3 3 3 3 2 3 3 3 2 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 2 3 3 3 3 2 2 3 3 2 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 2 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 2 3 3]\n",
      "171/171 [==============================] - 0s 94us/step\n",
      "[ 4.  3.  3.  2.  3.  3.  4.  2.  3.  2.  3.  4.  2.  3.  4.  3.  3.  2.\n",
      "  3.  4.  3.  3.  3.  3.  4.  2.  5.  3.  3.  2.  3.  3.  2.  2.  3.  2.\n",
      "  3.  5.  3.  3.  3.  3.  4.  4.  2.  2.  3.  4.  4.  3.  4.  4.  3.  3.\n",
      "  2.  2.  4.  3.  4.  3.  2.  2.  2.  3.  3.  3.  3.  2.  3.  4.  4.  3.\n",
      "  5.  4.  3.  3.  3.  4.  2.  3.  2.  4.  4.  3.  3.  3.  3.  3.  3.  3.\n",
      "  2.  3.  3.  3.  2.  1.  1.  3.  3.  1.  3.  3.  3.  3.  4.  2.  3.  4.\n",
      "  4.  2.  3.  4.  2.  3.  3.  4.  2.  3.  3.  3.  3.  3.  3.  2.  3.  3.\n",
      "  3.  3.  3.  3.  3.  1.  3.  3.  4.  3.  5.  3.  2.  3.  3.  3.  3.  3.\n",
      "  3.  3.  5.  3.  3.  2.  3.  3.  3.  3.  2.  3.  3.  5.  3.  3.  2.  4.\n",
      "  2.  3.  2.  3.  2.  4.  2.  3.  3.]\n",
      "Accuracy:  0.63742690163\n",
      "171/171 [==============================] - 0s 38us/step\n",
      "[[ 0  4  0  0  0]\n",
      " [ 0 18 17  0  0]\n",
      " [ 0  7 91  0  0]\n",
      " [ 0  0 28  0  0]\n",
      " [ 0  0  6  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(newmodel_my.predict(X_test_my, verbose=1))\n",
    "print(np.argmax(newmodel_my.predict(X_test_my, verbose=1),axis=1))\n",
    "\n",
    "scores_my = newmodel_my.evaluate(X_test_my, Y_test_my, verbose=1) \n",
    "print(y_test_my)\n",
    "print(\"Accuracy: \", scores_my[1])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cfm = confusion_matrix(np.array(y_test_my),np.array(np.argmax(newmodel_my.predict(X_test_my, verbose=1),axis=1)))\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
