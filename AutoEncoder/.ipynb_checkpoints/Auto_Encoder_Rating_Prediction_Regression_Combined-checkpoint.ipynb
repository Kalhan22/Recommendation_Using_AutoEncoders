{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils \n",
    "import numpy as np\n",
    "from tensorflow.python.ops.variables import trainable_variables\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train_my = genfromtxt('../UserData/655/trainX_item_655.csv', delimiter=',')\n",
    "y_train_my = genfromtxt('../UserData/655/trainY_item_655.csv', delimiter=',')\n",
    "X_test_my = genfromtxt('../UserData/655/testX_item_655.csv', delimiter=',')\n",
    "y_test_my = genfromtxt('../UserData/655/testY_item_655.csv', delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 19)\n"
     ]
    }
   ],
   "source": [
    "X_train_my = X_train_my.astype('float32') \n",
    "X_train_my = X_train_my.astype('float32')\n",
    "print(X_train_my.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_my = y_train_my\n",
    "\n",
    "Y_test_my = y_test_my\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_3:0\", shape=(?, 19), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_img_my = Input(shape=(19,))\n",
    "\n",
    "print(input_img_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_17/Relu:0\", shape=(?, 19), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_my = Dense(19, activation='relu')(input_img_my)\n",
    "print(x_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded1_my = Dense(15, activation='relu')(x_my)\n",
    "encoded2_my = Dense(12, activation='relu')(encoded1_my)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_my = Dense(10, activation='sigmoid')(encoded2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded2_my = Dense(12, activation='relu')(y_my)\n",
    "decoded1_my = Dense(15, activation='relu')(decoded2_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_my = Dense(19, activation='relu')(decoded1_my)\n",
    "autoencoder_my = Model(input_img_my, z_my)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x1a1baf6128>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "print(encoder_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 19)\n",
      "(412, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_my.shape)\n",
    "\n",
    "print(X_train_my.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412 samples, validate on 161 samples\n",
      "Epoch 1/100\n",
      "412/412 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.3274\n",
      "Epoch 2/100\n",
      "412/412 [==============================] - 0s 438us/step - loss: 0.2247 - val_loss: 0.1274\n",
      "Epoch 3/100\n",
      "412/412 [==============================] - 0s 461us/step - loss: 0.1150 - val_loss: 0.1124\n",
      "Epoch 4/100\n",
      "412/412 [==============================] - 0s 446us/step - loss: 0.1100 - val_loss: 0.1117\n",
      "Epoch 5/100\n",
      "412/412 [==============================] - 0s 447us/step - loss: 0.1097 - val_loss: 0.1114\n",
      "Epoch 6/100\n",
      "412/412 [==============================] - 0s 447us/step - loss: 0.1087 - val_loss: 0.1100\n",
      "Epoch 7/100\n",
      "412/412 [==============================] - 0s 452us/step - loss: 0.1075 - val_loss: 0.1105\n",
      "Epoch 8/100\n",
      "412/412 [==============================] - 0s 476us/step - loss: 0.1067 - val_loss: 0.1081\n",
      "Epoch 9/100\n",
      "412/412 [==============================] - 0s 456us/step - loss: 0.1057 - val_loss: 0.1063\n",
      "Epoch 10/100\n",
      "412/412 [==============================] - 0s 466us/step - loss: 0.1041 - val_loss: 0.1075\n",
      "Epoch 11/100\n",
      "412/412 [==============================] - 0s 486us/step - loss: 0.1023 - val_loss: 0.1026\n",
      "Epoch 12/100\n",
      "412/412 [==============================] - 0s 534us/step - loss: 0.0994 - val_loss: 0.1008\n",
      "Epoch 13/100\n",
      "412/412 [==============================] - 0s 454us/step - loss: 0.0969 - val_loss: 0.0967\n",
      "Epoch 14/100\n",
      "412/412 [==============================] - 0s 458us/step - loss: 0.0942 - val_loss: 0.0943\n",
      "Epoch 15/100\n",
      "412/412 [==============================] - 0s 608us/step - loss: 0.0918 - val_loss: 0.0921\n",
      "Epoch 16/100\n",
      "412/412 [==============================] - 0s 495us/step - loss: 0.0898 - val_loss: 0.0900\n",
      "Epoch 17/100\n",
      "412/412 [==============================] - 0s 620us/step - loss: 0.0878 - val_loss: 0.0886\n",
      "Epoch 18/100\n",
      "412/412 [==============================] - 0s 499us/step - loss: 0.0865 - val_loss: 0.0880\n",
      "Epoch 19/100\n",
      "412/412 [==============================] - 0s 600us/step - loss: 0.0852 - val_loss: 0.0865\n",
      "Epoch 20/100\n",
      "412/412 [==============================] - 0s 509us/step - loss: 0.0839 - val_loss: 0.0859\n",
      "Epoch 21/100\n",
      "412/412 [==============================] - 0s 446us/step - loss: 0.0828 - val_loss: 0.0837\n",
      "Epoch 22/100\n",
      "412/412 [==============================] - 0s 598us/step - loss: 0.0818 - val_loss: 0.0827\n",
      "Epoch 23/100\n",
      "412/412 [==============================] - 0s 451us/step - loss: 0.0811 - val_loss: 0.0832\n",
      "Epoch 24/100\n",
      "412/412 [==============================] - 0s 602us/step - loss: 0.0805 - val_loss: 0.0825\n",
      "Epoch 25/100\n",
      "412/412 [==============================] - 0s 455us/step - loss: 0.0796 - val_loss: 0.0815\n",
      "Epoch 26/100\n",
      "412/412 [==============================] - 0s 474us/step - loss: 0.0792 - val_loss: 0.0787\n",
      "Epoch 27/100\n",
      "412/412 [==============================] - 0s 548us/step - loss: 0.0787 - val_loss: 0.0788\n",
      "Epoch 28/100\n",
      "412/412 [==============================] - 0s 538us/step - loss: 0.0782 - val_loss: 0.0785\n",
      "Epoch 29/100\n",
      "412/412 [==============================] - 0s 554us/step - loss: 0.0779 - val_loss: 0.0797\n",
      "Epoch 30/100\n",
      "412/412 [==============================] - 0s 588us/step - loss: 0.0776 - val_loss: 0.0785\n",
      "Epoch 31/100\n",
      "412/412 [==============================] - 0s 458us/step - loss: 0.0774 - val_loss: 0.0768\n",
      "Epoch 32/100\n",
      "412/412 [==============================] - 0s 467us/step - loss: 0.0771 - val_loss: 0.0765\n",
      "Epoch 33/100\n",
      "412/412 [==============================] - 0s 511us/step - loss: 0.0769 - val_loss: 0.0767\n",
      "Epoch 34/100\n",
      "412/412 [==============================] - 0s 577us/step - loss: 0.0767 - val_loss: 0.0759\n",
      "Epoch 35/100\n",
      "412/412 [==============================] - 0s 560us/step - loss: 0.0765 - val_loss: 0.0771\n",
      "Epoch 36/100\n",
      "412/412 [==============================] - 0s 501us/step - loss: 0.0763 - val_loss: 0.0757\n",
      "Epoch 37/100\n",
      "412/412 [==============================] - ETA: 0s - loss: 0.076 - 0s 476us/step - loss: 0.0761 - val_loss: 0.0765\n",
      "Epoch 38/100\n",
      "412/412 [==============================] - 0s 625us/step - loss: 0.0759 - val_loss: 0.0760\n",
      "Epoch 39/100\n",
      "412/412 [==============================] - 0s 584us/step - loss: 0.0757 - val_loss: 0.0753\n",
      "Epoch 40/100\n",
      "412/412 [==============================] - 0s 605us/step - loss: 0.0755 - val_loss: 0.0751\n",
      "Epoch 41/100\n",
      "412/412 [==============================] - 0s 449us/step - loss: 0.0753 - val_loss: 0.0754\n",
      "Epoch 42/100\n",
      "412/412 [==============================] - 0s 647us/step - loss: 0.0752 - val_loss: 0.0751\n",
      "Epoch 43/100\n",
      "412/412 [==============================] - 0s 504us/step - loss: 0.0750 - val_loss: 0.0743\n",
      "Epoch 44/100\n",
      "412/412 [==============================] - 0s 661us/step - loss: 0.0748 - val_loss: 0.0747\n",
      "Epoch 45/100\n",
      "412/412 [==============================] - 0s 478us/step - loss: 0.0747 - val_loss: 0.0745\n",
      "Epoch 46/100\n",
      "412/412 [==============================] - 0s 632us/step - loss: 0.0745 - val_loss: 0.0739\n",
      "Epoch 47/100\n",
      "412/412 [==============================] - 0s 482us/step - loss: 0.0744 - val_loss: 0.0733\n",
      "Epoch 48/100\n",
      "412/412 [==============================] - 0s 600us/step - loss: 0.0743 - val_loss: 0.0736\n",
      "Epoch 49/100\n",
      "412/412 [==============================] - 0s 616us/step - loss: 0.0741 - val_loss: 0.0729\n",
      "Epoch 50/100\n",
      "412/412 [==============================] - 0s 571us/step - loss: 0.0740 - val_loss: 0.0738\n",
      "Epoch 51/100\n",
      "412/412 [==============================] - 0s 476us/step - loss: 0.0739 - val_loss: 0.0728\n",
      "Epoch 52/100\n",
      "412/412 [==============================] - 0s 687us/step - loss: 0.0739 - val_loss: 0.0728\n",
      "Epoch 53/100\n",
      "412/412 [==============================] - 0s 542us/step - loss: 0.0738 - val_loss: 0.0725\n",
      "Epoch 54/100\n",
      "412/412 [==============================] - 0s 375us/step - loss: 0.0737 - val_loss: 0.0730\n",
      "Epoch 55/100\n",
      "412/412 [==============================] - 0s 507us/step - loss: 0.0736 - val_loss: 0.0730\n",
      "Epoch 56/100\n",
      "412/412 [==============================] - 0s 661us/step - loss: 0.0737 - val_loss: 0.0736\n",
      "Epoch 57/100\n",
      "412/412 [==============================] - 0s 569us/step - loss: 0.0734 - val_loss: 0.0733\n",
      "Epoch 58/100\n",
      "412/412 [==============================] - 0s 357us/step - loss: 0.0735 - val_loss: 0.0736\n",
      "Epoch 59/100\n",
      "412/412 [==============================] - 0s 531us/step - loss: 0.0735 - val_loss: 0.0729\n",
      "Epoch 60/100\n",
      "412/412 [==============================] - 0s 448us/step - loss: 0.0734 - val_loss: 0.0727\n",
      "Epoch 61/100\n",
      "412/412 [==============================] - 0s 478us/step - loss: 0.0734 - val_loss: 0.0720\n",
      "Epoch 62/100\n",
      "412/412 [==============================] - 0s 494us/step - loss: 0.0733 - val_loss: 0.0723\n",
      "Epoch 63/100\n",
      "412/412 [==============================] - 0s 568us/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 64/100\n",
      "412/412 [==============================] - 0s 457us/step - loss: 0.0732 - val_loss: 0.0720\n",
      "Epoch 65/100\n",
      "412/412 [==============================] - 0s 449us/step - loss: 0.0730 - val_loss: 0.0722\n",
      "Epoch 66/100\n",
      "412/412 [==============================] - 0s 455us/step - loss: 0.0731 - val_loss: 0.0718\n",
      "Epoch 67/100\n",
      "412/412 [==============================] - 0s 477us/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 68/100\n",
      "412/412 [==============================] - 0s 483us/step - loss: 0.0730 - val_loss: 0.0721\n",
      "Epoch 69/100\n",
      "412/412 [==============================] - 0s 451us/step - loss: 0.0729 - val_loss: 0.0729\n",
      "Epoch 70/100\n",
      "412/412 [==============================] - 0s 449us/step - loss: 0.0728 - val_loss: 0.0715\n",
      "Epoch 71/100\n",
      "412/412 [==============================] - 0s 629us/step - loss: 0.0729 - val_loss: 0.0714\n",
      "Epoch 72/100\n",
      "412/412 [==============================] - 0s 482us/step - loss: 0.0727 - val_loss: 0.0730\n",
      "Epoch 73/100\n",
      "412/412 [==============================] - 0s 495us/step - loss: 0.0727 - val_loss: 0.0712\n",
      "Epoch 74/100\n",
      "412/412 [==============================] - 0s 481us/step - loss: 0.0726 - val_loss: 0.0715\n",
      "Epoch 75/100\n",
      "412/412 [==============================] - 0s 532us/step - loss: 0.0726 - val_loss: 0.0720\n",
      "Epoch 76/100\n",
      "412/412 [==============================] - 0s 603us/step - loss: 0.0726 - val_loss: 0.0721\n",
      "Epoch 77/100\n",
      "412/412 [==============================] - 0s 567us/step - loss: 0.0724 - val_loss: 0.0709\n",
      "Epoch 78/100\n",
      "412/412 [==============================] - 0s 566us/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 585us/step - loss: 0.0724 - val_loss: 0.0709\n",
      "Epoch 80/100\n",
      "412/412 [==============================] - 0s 589us/step - loss: 0.0723 - val_loss: 0.0711\n",
      "Epoch 81/100\n",
      "412/412 [==============================] - 0s 650us/step - loss: 0.0723 - val_loss: 0.0708\n",
      "Epoch 82/100\n",
      "412/412 [==============================] - 0s 638us/step - loss: 0.0721 - val_loss: 0.0709\n",
      "Epoch 83/100\n",
      "412/412 [==============================] - 0s 712us/step - loss: 0.0722 - val_loss: 0.0708\n",
      "Epoch 84/100\n",
      "412/412 [==============================] - 0s 677us/step - loss: 0.0722 - val_loss: 0.0708\n",
      "Epoch 85/100\n",
      "412/412 [==============================] - 0s 598us/step - loss: 0.0722 - val_loss: 0.0712\n",
      "Epoch 86/100\n",
      "412/412 [==============================] - 0s 485us/step - loss: 0.0720 - val_loss: 0.0709\n",
      "Epoch 87/100\n",
      "412/412 [==============================] - 0s 457us/step - loss: 0.0721 - val_loss: 0.0705\n",
      "Epoch 88/100\n",
      "412/412 [==============================] - 0s 440us/step - loss: 0.0720 - val_loss: 0.0711\n",
      "Epoch 89/100\n",
      "412/412 [==============================] - 0s 442us/step - loss: 0.0719 - val_loss: 0.0727\n",
      "Epoch 90/100\n",
      "412/412 [==============================] - 0s 443us/step - loss: 0.0719 - val_loss: 0.0707\n",
      "Epoch 91/100\n",
      "412/412 [==============================] - 0s 439us/step - loss: 0.0720 - val_loss: 0.0704\n",
      "Epoch 92/100\n",
      "412/412 [==============================] - 0s 456us/step - loss: 0.0719 - val_loss: 0.0712\n",
      "Epoch 93/100\n",
      "412/412 [==============================] - 0s 449us/step - loss: 0.0718 - val_loss: 0.0703\n",
      "Epoch 94/100\n",
      "412/412 [==============================] - 0s 448us/step - loss: 0.0717 - val_loss: 0.0722\n",
      "Epoch 95/100\n",
      "412/412 [==============================] - 0s 526us/step - loss: 0.0718 - val_loss: 0.0704\n",
      "Epoch 96/100\n",
      "412/412 [==============================] - 0s 677us/step - loss: 0.0718 - val_loss: 0.0704\n",
      "Epoch 97/100\n",
      "412/412 [==============================] - 0s 539us/step - loss: 0.0718 - val_loss: 0.0709\n",
      "Epoch 98/100\n",
      "412/412 [==============================] - 0s 491us/step - loss: 0.0716 - val_loss: 0.0702\n",
      "Epoch 99/100\n",
      "412/412 [==============================] - 0s 534us/step - loss: 0.0717 - val_loss: 0.0712\n",
      "Epoch 100/100\n",
      "412/412 [==============================] - 0s 673us/step - loss: 0.0717 - val_loss: 0.0703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1bb78780>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my)\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79834557  0.49876079  0.44607112 ...,  0.30656266  0.41368109\n",
      "   0.63750196]\n",
      " [ 0.88055962  0.38585302  0.96880364 ...,  0.07443769  0.29547665\n",
      "   0.26680735]\n",
      " [ 0.92218453  0.46425074  0.98602051 ...,  0.0724189   0.64115453\n",
      "   0.02437751]\n",
      " ..., \n",
      " [ 0.76869291  0.32332203  0.15231791 ...,  0.47106823  0.34973246\n",
      "   0.57209855]\n",
      " [ 0.55605251  0.45837945  0.42310259 ...,  0.37203136  0.3504661\n",
      "   0.74095112]\n",
      " [ 0.44700712  0.95248091  0.97659159 ...,  0.15367115  0.6686461\n",
      "   0.84472418]]\n"
     ]
    }
   ],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)\n",
    "print(reduced_representation_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412 samples, validate on 161 samples\n",
      "Epoch 1/100\n",
      "412/412 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0704\n",
      "Epoch 2/100\n",
      "412/412 [==============================] - 0s 476us/step - loss: 0.0715 - val_loss: 0.0722\n",
      "Epoch 3/100\n",
      "412/412 [==============================] - 0s 448us/step - loss: 0.0714 - val_loss: 0.0699\n",
      "Epoch 4/100\n",
      "412/412 [==============================] - 0s 597us/step - loss: 0.0715 - val_loss: 0.0698\n",
      "Epoch 5/100\n",
      "412/412 [==============================] - 0s 564us/step - loss: 0.0714 - val_loss: 0.0701\n",
      "Epoch 6/100\n",
      "412/412 [==============================] - 0s 563us/step - loss: 0.0713 - val_loss: 0.0698\n",
      "Epoch 7/100\n",
      "412/412 [==============================] - 0s 523us/step - loss: 0.0713 - val_loss: 0.0696\n",
      "Epoch 8/100\n",
      "412/412 [==============================] - 0s 659us/step - loss: 0.0713 - val_loss: 0.0700\n",
      "Epoch 9/100\n",
      "412/412 [==============================] - 0s 477us/step - loss: 0.0712 - val_loss: 0.0703\n",
      "Epoch 10/100\n",
      "412/412 [==============================] - 0s 498us/step - loss: 0.0712 - val_loss: 0.0696\n",
      "Epoch 11/100\n",
      "412/412 [==============================] - 0s 478us/step - loss: 0.0711 - val_loss: 0.0700\n",
      "Epoch 12/100\n",
      "412/412 [==============================] - 0s 665us/step - loss: 0.0711 - val_loss: 0.0697\n",
      "Epoch 13/100\n",
      "412/412 [==============================] - 0s 481us/step - loss: 0.0710 - val_loss: 0.0693\n",
      "Epoch 14/100\n",
      "412/412 [==============================] - 0s 527us/step - loss: 0.0710 - val_loss: 0.0698\n",
      "Epoch 15/100\n",
      "412/412 [==============================] - 0s 693us/step - loss: 0.0709 - val_loss: 0.0693\n",
      "Epoch 16/100\n",
      "412/412 [==============================] - 0s 451us/step - loss: 0.0708 - val_loss: 0.0692\n",
      "Epoch 17/100\n",
      "412/412 [==============================] - 0s 464us/step - loss: 0.0708 - val_loss: 0.0701\n",
      "Epoch 18/100\n",
      "412/412 [==============================] - 0s 485us/step - loss: 0.0709 - val_loss: 0.0687\n",
      "Epoch 19/100\n",
      "412/412 [==============================] - 0s 511us/step - loss: 0.0707 - val_loss: 0.0693\n",
      "Epoch 20/100\n",
      "412/412 [==============================] - 0s 472us/step - loss: 0.0707 - val_loss: 0.0688\n",
      "Epoch 21/100\n",
      "412/412 [==============================] - 0s 453us/step - loss: 0.0707 - val_loss: 0.0689\n",
      "Epoch 22/100\n",
      "412/412 [==============================] - 0s 522us/step - loss: 0.0707 - val_loss: 0.0688\n",
      "Epoch 23/100\n",
      "412/412 [==============================] - 0s 671us/step - loss: 0.0706 - val_loss: 0.0692\n",
      "Epoch 24/100\n",
      "412/412 [==============================] - 0s 478us/step - loss: 0.0707 - val_loss: 0.0687\n",
      "Epoch 25/100\n",
      "412/412 [==============================] - 0s 632us/step - loss: 0.0706 - val_loss: 0.0687\n",
      "Epoch 26/100\n",
      "412/412 [==============================] - 0s 332us/step - loss: 0.0707 - val_loss: 0.0689\n",
      "Epoch 27/100\n",
      "412/412 [==============================] - 0s 637us/step - loss: 0.0706 - val_loss: 0.0686\n",
      "Epoch 28/100\n",
      "412/412 [==============================] - 0s 373us/step - loss: 0.0705 - val_loss: 0.0707\n",
      "Epoch 29/100\n",
      "412/412 [==============================] - 0s 617us/step - loss: 0.0706 - val_loss: 0.0688\n",
      "Epoch 30/100\n",
      "412/412 [==============================] - 0s 346us/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 31/100\n",
      "412/412 [==============================] - 0s 633us/step - loss: 0.0706 - val_loss: 0.0687\n",
      "Epoch 32/100\n",
      "412/412 [==============================] - 0s 505us/step - loss: 0.0705 - val_loss: 0.0689\n",
      "Epoch 33/100\n",
      "412/412 [==============================] - 0s 614us/step - loss: 0.0705 - val_loss: 0.0689\n",
      "Epoch 34/100\n",
      "412/412 [==============================] - 0s 474us/step - loss: 0.0706 - val_loss: 0.0690\n",
      "Epoch 35/100\n",
      "412/412 [==============================] - 0s 585us/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 36/100\n",
      "412/412 [==============================] - 0s 485us/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 37/100\n",
      "412/412 [==============================] - 0s 537us/step - loss: 0.0705 - val_loss: 0.0685\n",
      "Epoch 38/100\n",
      "412/412 [==============================] - 0s 523us/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 39/100\n",
      "412/412 [==============================] - 0s 505us/step - loss: 0.0706 - val_loss: 0.0683\n",
      "Epoch 40/100\n",
      "412/412 [==============================] - 0s 541us/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 41/100\n",
      "412/412 [==============================] - 0s 445us/step - loss: 0.0706 - val_loss: 0.0684\n",
      "Epoch 42/100\n",
      "412/412 [==============================] - 0s 467us/step - loss: 0.0705 - val_loss: 0.0693\n",
      "Epoch 43/100\n",
      "412/412 [==============================] - 0s 458us/step - loss: 0.0705 - val_loss: 0.0689\n",
      "Epoch 44/100\n",
      "412/412 [==============================] - 0s 494us/step - loss: 0.0705 - val_loss: 0.0687\n",
      "Epoch 45/100\n",
      "412/412 [==============================] - 0s 469us/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 46/100\n",
      "412/412 [==============================] - 0s 493us/step - loss: 0.0704 - val_loss: 0.0685\n",
      "Epoch 47/100\n",
      "412/412 [==============================] - 0s 486us/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 48/100\n",
      "412/412 [==============================] - 0s 504us/step - loss: 0.0705 - val_loss: 0.0695\n",
      "Epoch 49/100\n",
      "412/412 [==============================] - 0s 459us/step - loss: 0.0705 - val_loss: 0.0690\n",
      "Epoch 50/100\n",
      "412/412 [==============================] - 0s 461us/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 51/100\n",
      "412/412 [==============================] - 0s 474us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 52/100\n",
      "412/412 [==============================] - 0s 628us/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 53/100\n",
      "412/412 [==============================] - 0s 450us/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 54/100\n",
      "412/412 [==============================] - 0s 556us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 55/100\n",
      "412/412 [==============================] - 0s 709us/step - loss: 0.0705 - val_loss: 0.0694\n",
      "Epoch 56/100\n",
      "412/412 [==============================] - 0s 642us/step - loss: 0.0705 - val_loss: 0.0692\n",
      "Epoch 57/100\n",
      "412/412 [==============================] - 0s 594us/step - loss: 0.0706 - val_loss: 0.0682\n",
      "Epoch 58/100\n",
      "412/412 [==============================] - 0s 457us/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 59/100\n",
      "412/412 [==============================] - 0s 449us/step - loss: 0.0704 - val_loss: 0.0685\n",
      "Epoch 60/100\n",
      "412/412 [==============================] - 0s 621us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 61/100\n",
      "412/412 [==============================] - 0s 551us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 62/100\n",
      "412/412 [==============================] - 0s 643us/step - loss: 0.0705 - val_loss: 0.0684\n",
      "Epoch 63/100\n",
      "412/412 [==============================] - 0s 606us/step - loss: 0.0704 - val_loss: 0.0694\n",
      "Epoch 64/100\n",
      "412/412 [==============================] - 0s 467us/step - loss: 0.0705 - val_loss: 0.0687\n",
      "Epoch 65/100\n",
      "412/412 [==============================] - 0s 580us/step - loss: 0.0704 - val_loss: 0.0697\n",
      "Epoch 66/100\n",
      "412/412 [==============================] - 0s 601us/step - loss: 0.0705 - val_loss: 0.0681\n",
      "Epoch 67/100\n",
      "412/412 [==============================] - 0s 463us/step - loss: 0.0705 - val_loss: 0.0685\n",
      "Epoch 68/100\n",
      "412/412 [==============================] - ETA: 0s - loss: 0.070 - 0s 623us/step - loss: 0.0705 - val_loss: 0.0683\n",
      "Epoch 69/100\n",
      "412/412 [==============================] - 0s 663us/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 70/100\n",
      "412/412 [==============================] - 0s 471us/step - loss: 0.0705 - val_loss: 0.0683\n",
      "Epoch 71/100\n",
      "412/412 [==============================] - 0s 626us/step - loss: 0.0704 - val_loss: 0.0688\n",
      "Epoch 72/100\n",
      "412/412 [==============================] - 0s 574us/step - loss: 0.0704 - val_loss: 0.0681\n",
      "Epoch 73/100\n",
      "412/412 [==============================] - 0s 550us/step - loss: 0.0704 - val_loss: 0.0689\n",
      "Epoch 74/100\n",
      "412/412 [==============================] - 0s 643us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 75/100\n",
      "412/412 [==============================] - 0s 488us/step - loss: 0.0704 - val_loss: 0.0686\n",
      "Epoch 76/100\n",
      "412/412 [==============================] - 0s 417us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 77/100\n",
      "412/412 [==============================] - 0s 612us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 78/100\n",
      "412/412 [==============================] - 0s 501us/step - loss: 0.0704 - val_loss: 0.0698\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 460us/step - loss: 0.0704 - val_loss: 0.0684\n",
      "Epoch 80/100\n",
      "412/412 [==============================] - 0s 571us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 81/100\n",
      "412/412 [==============================] - 0s 494us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 82/100\n",
      "412/412 [==============================] - 0s 498us/step - loss: 0.0704 - val_loss: 0.0681\n",
      "Epoch 83/100\n",
      "412/412 [==============================] - 0s 542us/step - loss: 0.0704 - val_loss: 0.0686\n",
      "Epoch 84/100\n",
      "412/412 [==============================] - 0s 460us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 85/100\n",
      "412/412 [==============================] - 0s 508us/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 86/100\n",
      "412/412 [==============================] - 0s 534us/step - loss: 0.0704 - val_loss: 0.0681\n",
      "Epoch 87/100\n",
      "412/412 [==============================] - 0s 596us/step - loss: 0.0703 - val_loss: 0.0685\n",
      "Epoch 88/100\n",
      "412/412 [==============================] - 0s 510us/step - loss: 0.0704 - val_loss: 0.0684\n",
      "Epoch 89/100\n",
      "412/412 [==============================] - 0s 426us/step - loss: 0.0704 - val_loss: 0.0681\n",
      "Epoch 90/100\n",
      "412/412 [==============================] - 0s 671us/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 91/100\n",
      "412/412 [==============================] - 0s 576us/step - loss: 0.0704 - val_loss: 0.0687\n",
      "Epoch 92/100\n",
      "412/412 [==============================] - 0s 586us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 93/100\n",
      "412/412 [==============================] - 0s 506us/step - loss: 0.0704 - val_loss: 0.0691\n",
      "Epoch 94/100\n",
      "412/412 [==============================] - 0s 553us/step - loss: 0.0704 - val_loss: 0.0681\n",
      "Epoch 95/100\n",
      "412/412 [==============================] - 0s 510us/step - loss: 0.0704 - val_loss: 0.0703\n",
      "Epoch 96/100\n",
      "412/412 [==============================] - 0s 612us/step - loss: 0.0704 - val_loss: 0.0680\n",
      "Epoch 97/100\n",
      "412/412 [==============================] - 0s 597us/step - loss: 0.0704 - val_loss: 0.0685\n",
      "Epoch 98/100\n",
      "412/412 [==============================] - 0s 461us/step - loss: 0.0704 - val_loss: 0.0683\n",
      "Epoch 99/100\n",
      "412/412 [==============================] - 0s 456us/step - loss: 0.0704 - val_loss: 0.0682\n",
      "Epoch 100/100\n",
      "412/412 [==============================] - 0s 574us/step - loss: 0.0704 - val_loss: 0.0680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1be43cc0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder is the model of the autoencoder slice in the middle \n",
    "encoder_my = Model(input_img_my, y_my)\n",
    "\n",
    "autoencoder_my.compile(loss='mse', optimizer='rmsprop') # reporting the loss\n",
    "\n",
    "autoencoder_my.fit(X_train_my, X_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=10,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, X_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want an encoded flatten representation of every test MNIST\n",
    "reduced_representation_my =encoder_my.predict(X_test_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out2_my = Dense(1, activation='linear')(encoder_my.output)\n",
    "newmodel_my = Model(encoder_my.input,out2_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newmodel_my.compile(loss='mean_squared_error', optimizer='rmsprop', \n",
    "          metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412 samples, validate on 161 samples\n",
      "Epoch 1/100\n",
      "412/412 [==============================] - 0s 724us/step - loss: 15.6238 - acc: 0.0000e+00 - val_loss: 13.5836 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 13.8084 - acc: 0.0000e+00 - val_loss: 12.4002 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "412/412 [==============================] - 0s 67us/step - loss: 12.6681 - acc: 0.0000e+00 - val_loss: 11.5247 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 11.8037 - acc: 0.0000e+00 - val_loss: 10.7906 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 11.0639 - acc: 0.0000e+00 - val_loss: 10.1187 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "412/412 [==============================] - 0s 66us/step - loss: 10.3954 - acc: 0.0000e+00 - val_loss: 9.5011 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "412/412 [==============================] - 0s 75us/step - loss: 9.7762 - acc: 0.0000e+00 - val_loss: 8.9717 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "412/412 [==============================] - 0s 76us/step - loss: 9.2612 - acc: 0.0000e+00 - val_loss: 8.5360 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "412/412 [==============================] - 0s 79us/step - loss: 8.8320 - acc: 0.0000e+00 - val_loss: 8.1551 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "412/412 [==============================] - 0s 64us/step - loss: 8.4392 - acc: 0.0000e+00 - val_loss: 7.7801 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "412/412 [==============================] - 0s 69us/step - loss: 8.0534 - acc: 0.0000e+00 - val_loss: 7.4238 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 7.6836 - acc: 0.0000e+00 - val_loss: 7.0702 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 7.3144 - acc: 0.0000e+00 - val_loss: 6.7141 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "412/412 [==============================] - 0s 98us/step - loss: 6.9430 - acc: 0.0024 - val_loss: 6.3553 - val_acc: 0.0062\n",
      "Epoch 15/100\n",
      "412/412 [==============================] - 0s 68us/step - loss: 6.5712 - acc: 0.0073 - val_loss: 6.0068 - val_acc: 0.0124\n",
      "Epoch 16/100\n",
      "412/412 [==============================] - 0s 78us/step - loss: 6.2141 - acc: 0.0073 - val_loss: 5.6743 - val_acc: 0.0248\n",
      "Epoch 17/100\n",
      "412/412 [==============================] - 0s 68us/step - loss: 5.8809 - acc: 0.0146 - val_loss: 5.3820 - val_acc: 0.0248\n",
      "Epoch 18/100\n",
      "412/412 [==============================] - 0s 73us/step - loss: 5.5864 - acc: 0.0146 - val_loss: 5.1155 - val_acc: 0.0248\n",
      "Epoch 19/100\n",
      "412/412 [==============================] - 0s 70us/step - loss: 5.3203 - acc: 0.0146 - val_loss: 4.8791 - val_acc: 0.0248\n",
      "Epoch 20/100\n",
      "412/412 [==============================] - 0s 67us/step - loss: 5.0845 - acc: 0.0146 - val_loss: 4.6662 - val_acc: 0.0248\n",
      "Epoch 21/100\n",
      "412/412 [==============================] - 0s 61us/step - loss: 4.8730 - acc: 0.0146 - val_loss: 4.4779 - val_acc: 0.0248\n",
      "Epoch 22/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 4.6846 - acc: 0.0146 - val_loss: 4.3052 - val_acc: 0.0248\n",
      "Epoch 23/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 4.5120 - acc: 0.0146 - val_loss: 4.1480 - val_acc: 0.0248\n",
      "Epoch 24/100\n",
      "412/412 [==============================] - 0s 60us/step - loss: 4.3546 - acc: 0.0146 - val_loss: 4.0030 - val_acc: 0.0248\n",
      "Epoch 25/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 4.2090 - acc: 0.0146 - val_loss: 3.8684 - val_acc: 0.0248\n",
      "Epoch 26/100\n",
      "412/412 [==============================] - 0s 51us/step - loss: 4.0738 - acc: 0.0146 - val_loss: 3.7460 - val_acc: 0.0248\n",
      "Epoch 27/100\n",
      "412/412 [==============================] - 0s 64us/step - loss: 3.9500 - acc: 0.0146 - val_loss: 3.6316 - val_acc: 0.0248\n",
      "Epoch 28/100\n",
      "412/412 [==============================] - 0s 61us/step - loss: 3.8329 - acc: 0.0146 - val_loss: 3.5184 - val_acc: 0.0248\n",
      "Epoch 29/100\n",
      "412/412 [==============================] - 0s 60us/step - loss: 3.7168 - acc: 0.0146 - val_loss: 3.4122 - val_acc: 0.0248\n",
      "Epoch 30/100\n",
      "412/412 [==============================] - 0s 65us/step - loss: 3.6056 - acc: 0.0146 - val_loss: 3.3021 - val_acc: 0.0248\n",
      "Epoch 31/100\n",
      "412/412 [==============================] - 0s 65us/step - loss: 3.4909 - acc: 0.0146 - val_loss: 3.1949 - val_acc: 0.0248\n",
      "Epoch 32/100\n",
      "412/412 [==============================] - 0s 59us/step - loss: 3.3791 - acc: 0.0146 - val_loss: 3.0930 - val_acc: 0.0248\n",
      "Epoch 33/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 3.2726 - acc: 0.0146 - val_loss: 2.9892 - val_acc: 0.0248\n",
      "Epoch 34/100\n",
      "412/412 [==============================] - 0s 64us/step - loss: 3.1658 - acc: 0.0146 - val_loss: 2.8932 - val_acc: 0.0248\n",
      "Epoch 35/100\n",
      "412/412 [==============================] - 0s 61us/step - loss: 3.0665 - acc: 0.0146 - val_loss: 2.8011 - val_acc: 0.0248\n",
      "Epoch 36/100\n",
      "412/412 [==============================] - 0s 63us/step - loss: 2.9713 - acc: 0.0146 - val_loss: 2.7150 - val_acc: 0.0248\n",
      "Epoch 37/100\n",
      "412/412 [==============================] - 0s 63us/step - loss: 2.8816 - acc: 0.0146 - val_loss: 2.6313 - val_acc: 0.0248\n",
      "Epoch 38/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 2.7944 - acc: 0.0146 - val_loss: 2.5509 - val_acc: 0.0248\n",
      "Epoch 39/100\n",
      "412/412 [==============================] - 0s 61us/step - loss: 2.7101 - acc: 0.0146 - val_loss: 2.4704 - val_acc: 0.0248\n",
      "Epoch 40/100\n",
      "412/412 [==============================] - 0s 63us/step - loss: 2.6262 - acc: 0.0146 - val_loss: 2.3947 - val_acc: 0.0248\n",
      "Epoch 41/100\n",
      "412/412 [==============================] - 0s 68us/step - loss: 2.5467 - acc: 0.0437 - val_loss: 2.3199 - val_acc: 0.2919\n",
      "Epoch 42/100\n",
      "412/412 [==============================] - 0s 67us/step - loss: 2.4683 - acc: 0.2500 - val_loss: 2.2486 - val_acc: 0.2919\n",
      "Epoch 43/100\n",
      "412/412 [==============================] - 0s 75us/step - loss: 2.3931 - acc: 0.2573 - val_loss: 2.1785 - val_acc: 0.2919\n",
      "Epoch 44/100\n",
      "412/412 [==============================] - 0s 68us/step - loss: 2.3192 - acc: 0.2573 - val_loss: 2.1100 - val_acc: 0.2919\n",
      "Epoch 45/100\n",
      "412/412 [==============================] - 0s 79us/step - loss: 2.2470 - acc: 0.2573 - val_loss: 2.0455 - val_acc: 0.2919\n",
      "Epoch 46/100\n",
      "412/412 [==============================] - 0s 91us/step - loss: 2.1785 - acc: 0.2573 - val_loss: 1.9805 - val_acc: 0.2919\n",
      "Epoch 47/100\n",
      "412/412 [==============================] - ETA: 0s - loss: 2.2529 - acc: 0.289 - 0s 57us/step - loss: 2.1097 - acc: 0.2573 - val_loss: 1.9189 - val_acc: 0.2919\n",
      "Epoch 48/100\n",
      "412/412 [==============================] - 0s 74us/step - loss: 2.0443 - acc: 0.2573 - val_loss: 1.8590 - val_acc: 0.2919\n",
      "Epoch 49/100\n",
      "412/412 [==============================] - 0s 80us/step - loss: 1.9803 - acc: 0.2573 - val_loss: 1.8002 - val_acc: 0.2919\n",
      "Epoch 50/100\n",
      "412/412 [==============================] - 0s 74us/step - loss: 1.9172 - acc: 0.2573 - val_loss: 1.7387 - val_acc: 0.2919\n",
      "Epoch 51/100\n",
      "412/412 [==============================] - 0s 64us/step - loss: 1.8522 - acc: 0.2573 - val_loss: 1.6818 - val_acc: 0.2919\n",
      "Epoch 52/100\n",
      "412/412 [==============================] - 0s 74us/step - loss: 1.7914 - acc: 0.2573 - val_loss: 1.6265 - val_acc: 0.2919\n",
      "Epoch 53/100\n",
      "412/412 [==============================] - 0s 75us/step - loss: 1.7327 - acc: 0.2573 - val_loss: 1.5777 - val_acc: 0.2919\n",
      "Epoch 54/100\n",
      "412/412 [==============================] - 0s 66us/step - loss: 1.6794 - acc: 0.2573 - val_loss: 1.5243 - val_acc: 0.2919\n",
      "Epoch 55/100\n",
      "412/412 [==============================] - 0s 70us/step - loss: 1.6223 - acc: 0.2573 - val_loss: 1.4737 - val_acc: 0.2919\n",
      "Epoch 56/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 1.5679 - acc: 0.2573 - val_loss: 1.4256 - val_acc: 0.2919\n",
      "Epoch 57/100\n",
      "412/412 [==============================] - 0s 63us/step - loss: 1.5157 - acc: 0.2573 - val_loss: 1.3767 - val_acc: 0.2919\n",
      "Epoch 58/100\n",
      "412/412 [==============================] - ETA: 0s - loss: 1.2552 - acc: 0.226 - 0s 53us/step - loss: 1.4631 - acc: 0.2573 - val_loss: 1.3314 - val_acc: 0.2919\n",
      "Epoch 59/100\n",
      "412/412 [==============================] - 0s 43us/step - loss: 1.4138 - acc: 0.2573 - val_loss: 1.2861 - val_acc: 0.2919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "412/412 [==============================] - 0s 77us/step - loss: 1.3645 - acc: 0.2573 - val_loss: 1.2419 - val_acc: 0.2919\n",
      "Epoch 61/100\n",
      "412/412 [==============================] - 0s 52us/step - loss: 1.3167 - acc: 0.2573 - val_loss: 1.2014 - val_acc: 0.2919\n",
      "Epoch 62/100\n",
      "412/412 [==============================] - 0s 53us/step - loss: 1.2723 - acc: 0.2573 - val_loss: 1.1613 - val_acc: 0.2919\n",
      "Epoch 63/100\n",
      "412/412 [==============================] - 0s 48us/step - loss: 1.2286 - acc: 0.2573 - val_loss: 1.1230 - val_acc: 0.2919\n",
      "Epoch 64/100\n",
      "412/412 [==============================] - 0s 50us/step - loss: 1.1862 - acc: 0.2573 - val_loss: 1.0866 - val_acc: 0.2919\n",
      "Epoch 65/100\n",
      "412/412 [==============================] - 0s 49us/step - loss: 1.1459 - acc: 0.2573 - val_loss: 1.0491 - val_acc: 0.2919\n",
      "Epoch 66/100\n",
      "412/412 [==============================] - 0s 50us/step - loss: 1.1045 - acc: 0.2573 - val_loss: 1.0135 - val_acc: 0.2919\n",
      "Epoch 67/100\n",
      "412/412 [==============================] - 0s 45us/step - loss: 1.0656 - acc: 0.2573 - val_loss: 0.9850 - val_acc: 0.2919\n",
      "Epoch 68/100\n",
      "412/412 [==============================] - 0s 51us/step - loss: 1.0331 - acc: 0.2573 - val_loss: 0.9535 - val_acc: 0.2919\n",
      "Epoch 69/100\n",
      "412/412 [==============================] - 0s 47us/step - loss: 0.9978 - acc: 0.2573 - val_loss: 0.9225 - val_acc: 0.2919\n",
      "Epoch 70/100\n",
      "412/412 [==============================] - 0s 51us/step - loss: 0.9630 - acc: 0.2573 - val_loss: 0.8939 - val_acc: 0.2919\n",
      "Epoch 71/100\n",
      "412/412 [==============================] - 0s 46us/step - loss: 0.9307 - acc: 0.2573 - val_loss: 0.8666 - val_acc: 0.2919\n",
      "Epoch 72/100\n",
      "412/412 [==============================] - 0s 64us/step - loss: 0.8998 - acc: 0.2573 - val_loss: 0.8404 - val_acc: 0.2919\n",
      "Epoch 73/100\n",
      "412/412 [==============================] - 0s 78us/step - loss: 0.8698 - acc: 0.2573 - val_loss: 0.8151 - val_acc: 0.2919\n",
      "Epoch 74/100\n",
      "412/412 [==============================] - 0s 71us/step - loss: 0.8408 - acc: 0.2573 - val_loss: 0.7943 - val_acc: 0.2919\n",
      "Epoch 75/100\n",
      "412/412 [==============================] - 0s 80us/step - loss: 0.8163 - acc: 0.2573 - val_loss: 0.7725 - val_acc: 0.2919\n",
      "Epoch 76/100\n",
      "412/412 [==============================] - 0s 73us/step - loss: 0.7908 - acc: 0.2573 - val_loss: 0.7524 - val_acc: 0.2919\n",
      "Epoch 77/100\n",
      "412/412 [==============================] - 0s 74us/step - loss: 0.7673 - acc: 0.2573 - val_loss: 0.7342 - val_acc: 0.2919\n",
      "Epoch 78/100\n",
      "412/412 [==============================] - 0s 77us/step - loss: 0.7452 - acc: 0.2573 - val_loss: 0.7143 - val_acc: 0.2919\n",
      "Epoch 79/100\n",
      "412/412 [==============================] - 0s 59us/step - loss: 0.7217 - acc: 0.2573 - val_loss: 0.6985 - val_acc: 0.2919\n",
      "Epoch 80/100\n",
      "412/412 [==============================] - 0s 49us/step - loss: 0.7024 - acc: 0.4539 - val_loss: 0.6840 - val_acc: 0.5466\n",
      "Epoch 81/100\n",
      "412/412 [==============================] - 0s 58us/step - loss: 0.6844 - acc: 0.5534 - val_loss: 0.6703 - val_acc: 0.5466\n",
      "Epoch 82/100\n",
      "412/412 [==============================] - 0s 43us/step - loss: 0.6673 - acc: 0.5534 - val_loss: 0.6571 - val_acc: 0.5466\n",
      "Epoch 83/100\n",
      "412/412 [==============================] - 0s 52us/step - loss: 0.6505 - acc: 0.5534 - val_loss: 0.6459 - val_acc: 0.5466\n",
      "Epoch 84/100\n",
      "412/412 [==============================] - 0s 52us/step - loss: 0.6359 - acc: 0.5534 - val_loss: 0.6352 - val_acc: 0.5466\n",
      "Epoch 85/100\n",
      "412/412 [==============================] - 0s 48us/step - loss: 0.6219 - acc: 0.5534 - val_loss: 0.6268 - val_acc: 0.5466\n",
      "Epoch 86/100\n",
      "412/412 [==============================] - 0s 46us/step - loss: 0.6100 - acc: 0.5534 - val_loss: 0.6176 - val_acc: 0.5466\n",
      "Epoch 87/100\n",
      "412/412 [==============================] - 0s 43us/step - loss: 0.5974 - acc: 0.5534 - val_loss: 0.6113 - val_acc: 0.5466\n",
      "Epoch 88/100\n",
      "412/412 [==============================] - 0s 47us/step - loss: 0.5878 - acc: 0.5534 - val_loss: 0.6058 - val_acc: 0.5466\n",
      "Epoch 89/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 0.5791 - acc: 0.5534 - val_loss: 0.6012 - val_acc: 0.5466\n",
      "Epoch 90/100\n",
      "412/412 [==============================] - 0s 52us/step - loss: 0.5714 - acc: 0.5534 - val_loss: 0.5973 - val_acc: 0.5466\n",
      "Epoch 91/100\n",
      "412/412 [==============================] - 0s 47us/step - loss: 0.5650 - acc: 0.5534 - val_loss: 0.5953 - val_acc: 0.5466\n",
      "Epoch 92/100\n",
      "412/412 [==============================] - 0s 59us/step - loss: 0.5603 - acc: 0.5534 - val_loss: 0.5930 - val_acc: 0.5466\n",
      "Epoch 93/100\n",
      "412/412 [==============================] - ETA: 0s - loss: 0.6565 - acc: 0.507 - 0s 67us/step - loss: 0.5549 - acc: 0.5534 - val_loss: 0.5913 - val_acc: 0.5466\n",
      "Epoch 94/100\n",
      "412/412 [==============================] - 0s 66us/step - loss: 0.5500 - acc: 0.5534 - val_loss: 0.5909 - val_acc: 0.5466\n",
      "Epoch 95/100\n",
      "412/412 [==============================] - 0s 80us/step - loss: 0.5470 - acc: 0.5534 - val_loss: 0.5910 - val_acc: 0.5466\n",
      "Epoch 96/100\n",
      "412/412 [==============================] - 0s 62us/step - loss: 0.5443 - acc: 0.5534 - val_loss: 0.5910 - val_acc: 0.5466\n",
      "Epoch 97/100\n",
      "412/412 [==============================] - 0s 82us/step - loss: 0.5424 - acc: 0.5534 - val_loss: 0.5882 - val_acc: 0.5466\n",
      "Epoch 98/100\n",
      "412/412 [==============================] - 0s 121us/step - loss: 0.5394 - acc: 0.5534 - val_loss: 0.5873 - val_acc: 0.5466\n",
      "Epoch 99/100\n",
      "412/412 [==============================] - 0s 50us/step - loss: 0.5362 - acc: 0.5534 - val_loss: 0.5839 - val_acc: 0.5466\n",
      "Epoch 100/100\n",
      "412/412 [==============================] - 0s 49us/step - loss: 0.5327 - acc: 0.5534 - val_loss: 0.5734 - val_acc: 0.5466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1c3bf5f8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel_my.fit(X_train_my, Y_train_my,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(X_test_my, Y_test_my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 713us/step\n",
      "0.573429348157\n",
      "161/161 [==============================] - 0s 85us/step\n",
      "[ 2.87580514  2.86412406  2.8722527   2.83896685  2.87486386  2.85365582\n",
      "  2.80488586  2.88166881  2.87453127  2.77994394  2.8660717   2.86221933\n",
      "  2.81646752  2.8736589   2.85724235  2.86798716  2.78546596  2.7421174\n",
      "  2.8812604   2.8615098   2.87608361  2.88139272  2.86322308  2.84928679\n",
      "  2.84533739  2.87483859  2.86303043  2.85966897  2.87343645  2.87857723\n",
      "  2.83781624  2.85721445  2.85099936  2.8748126   2.81747365  2.81236458\n",
      "  2.86678362  2.85627913  2.77913475  2.86706424  2.86636305  2.84629631\n",
      "  2.79666114  2.8451705   2.87454128  2.86723852  2.84352756  2.83941531\n",
      "  2.8334372   2.86636138  2.82223153  2.81053972  2.84033799  2.84992886\n",
      "  2.81393075  2.8565824   2.80064487  2.79027534  2.81554413  2.7945013\n",
      "  2.86130381  2.84920359  2.87383103  2.83346748  2.82494926  2.84299946\n",
      "  2.86938477  2.84242415  2.86451006  2.88505697  2.85939002  2.8722806\n",
      "  2.88708305  2.8747685   2.85839391  2.85807872  2.8699367   2.87577033\n",
      "  2.87244081  2.77369785  2.81918907  2.80063033  2.87450671  2.84254766\n",
      "  2.83558345  2.87343049  2.87500763  2.82695293  2.87548041  2.88288999\n",
      "  2.83162308  2.85468745  2.84921384  2.82168436  2.83923411  2.81359625\n",
      "  2.85786319  2.7875061   2.84811211  2.80493474  2.84520388  2.8036828\n",
      "  2.84236455  2.84227467  2.78845263  2.81348896  2.79676127  2.79802227\n",
      "  2.80250335  2.77385879  2.72608209  2.75064516  2.8269043   2.8473928\n",
      "  2.84264708  2.79765773  2.86355734  2.85580444  2.83972692  2.85054612\n",
      "  2.84780741  2.81737852  2.8561995   2.84369636  2.81943846  2.86468267\n",
      "  2.85944057  2.83485293  2.84726453  2.82145596  2.8512156   2.87650871\n",
      "  2.76215816  2.84772134  2.86999965  2.8014977   2.85196137  2.85378194\n",
      "  2.83813024  2.87429428  2.77404761  2.86113834  2.86977863  2.85196137\n",
      "  2.80049467  2.75161505  2.78630328  2.81609344  2.79629183  2.85547352\n",
      "  2.74245644  2.84795284  2.86299491  2.81911159  2.84411526  2.84616637\n",
      "  2.82882595  2.85157943  2.86901736  2.85359478  2.83364344]\n",
      "161/161 [==============================] - 0s 86us/step\n",
      "[ 3.  3.  3.  3.  4.  3.  3.  4.  2.  2.  3.  5.  2.  3.  3.  3.  2.  2.\n",
      "  3.  2.  5.  4.  4.  3.  4.  3.  3.  3.  5.  3.  3.  3.  3.  4.  2.  2.\n",
      "  3.  3.  3.  2.  4.  2.  2.  3.  3.  2.  4.  3.  2.  4.  3.  3.  3.  3.\n",
      "  3.  3.  2.  2.  2.  2.  3.  2.  2.  4.  3.  3.  2.  3.  3.  4.  4.  3.\n",
      "  3.  3.  5.  2.  3.  3.  2.  2.  2.  3.  3.  3.  4.  3.  3.  2.  3.  4.\n",
      "  3.  2.  2.  3.  4.  1.  2.  3.  3.  3.  2.  1.  2.  3.  3.  2.  2.  2.\n",
      "  2.  2.  2.  3.  2.  2.  3.  4.  3.  3.  3.  3.  3.  3.  2.  3.  3.  3.\n",
      "  1.  2.  3.  1.  4.  3.  3.  3.  2.  3.  3.  3.  3.  3.  3.  3.  5.  3.\n",
      "  3.  2.  2.  3.  3.  3.  2.  3.  3.  3.  3.  2.  2.  3.  2.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "#print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(newmodel_my.predict(X_test_my, verbose=1).flatten(), Y_test_my)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "print(newmodel_my.predict(X_test_my, verbose=1).flatten())\n",
    "\n",
    "#print('Rounded')\n",
    "#print(np.around(newmodel_my.predict(X_test_my, verbose=1).flatten(),decimals=0))\n",
    "\n",
    "scores_my = newmodel_my.evaluate(X_test_my, Y_test_my, verbose=1) \n",
    "print(y_test_my)\n",
    "\n",
    "#print(\"Accuracy: \", scores_my[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
